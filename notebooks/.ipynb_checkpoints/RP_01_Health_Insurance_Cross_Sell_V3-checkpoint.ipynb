{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba1e0d7",
   "metadata": {},
   "source": [
    "# PA004 - HEALTH INSURANCE CROS-SELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96817c",
   "metadata": {},
   "source": [
    "## 0 - IMPORTS AND FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17f6ae08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:52:49.556132Z",
     "start_time": "2023-02-05T21:52:45.540249Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perot\\anaconda3\\envs\\health_insurance_venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import optuna\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import lightgbm              as lgbm\n",
    "import scikitplot            as skplt\n",
    "import matplotlib.patches    as mpatches\n",
    "import matplotlib.pyplot     as plt\n",
    "import numpy                 as np\n",
    "import plotly.express        as px\n",
    "import pandas                as pd\n",
    "import seaborn               as sns\n",
    "\n",
    "from IPython.core.display    import HTML\n",
    "from IPython.display         import Image\n",
    "from xgboost                 import XGBClassifier\n",
    "from sklearn.metrics         import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from optuna.integration      import LightGBMPruningCallback\n",
    "from imblearn.over_sampling  import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,precision_score, roc_auc_score,classification_report,roc_curve,auc\n",
    "\n",
    "from sklearn                 import preprocessing             as pp\n",
    "from sklearn                 import model_selection           as ms\n",
    "from sklearn                 import neighbors                 as nh\n",
    "from sklearn                 import ensemble                  as en\n",
    "\n",
    "\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cdef58",
   "metadata": {},
   "source": [
    "### 0.1 - HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc80304a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:52:49.602228Z",
     "start_time": "2023-02-05T21:52:49.558132Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def recall_at_k (data, k=20000):\n",
    "    # Reset Index\n",
    "    data = data.reset_index( drop=True )\n",
    "\n",
    "    # Create Ranking Order\n",
    "    data['ranking'] = data.index + 1\n",
    "\n",
    "    data['recall_at_k'] = data['response'].cumsum() / data['response'].sum()\n",
    "\n",
    "    return data.loc[k, 'recall_at_k'] \n",
    "\n",
    "def precision_at_k (data, k=20000):\n",
    "    # Reset Index\n",
    "    data = data.reset_index( drop=True )\n",
    "\n",
    "    # Create Ranking Order\n",
    "    data['ranking'] = data.index + 1\n",
    "\n",
    "    data['precision_at_k'] = data['response'].cumsum() / data['ranking']\n",
    "\n",
    "    return data.loc[k, 'precision_at_k']\n",
    "\n",
    "def cramer_v( x, y):\n",
    "    cm = pd.crosstab( x, y).values   \n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape    \n",
    "    \n",
    "    chi2 = ss.chi2_contingency( cm )[0]\n",
    "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1) \n",
    "    \n",
    "    return np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) )\n",
    "\n",
    "def prediction_score(model, data):\n",
    "    # Separating train and validation dataset for each kfold\n",
    "    x_train = data.drop(columns=['response'])\n",
    "    y_train = data['response']\n",
    "    \n",
    "    # prediction probability (score)\n",
    "    yhat_proba = model.predict_proba(x_train)[:, 1].tolist()\n",
    "    \n",
    "    # merging score to dataset\n",
    "    data_scored = data.copy()\n",
    "    data_scored['score'] = yhat_proba\n",
    "    \n",
    "    # sort\n",
    "    data_scored = data_scored.sort_values('score', ascending=False)\n",
    "    \n",
    "    # precision and recall\n",
    "    data_scored = data_scored.reset_index(drop=True)\n",
    "    data_scored['n_samples'] = data_scored.index + 1\n",
    "    data_scored['precision_at_k'] = data_scored['response'].cumsum() / data_scored['n_samples']\n",
    "    data_scored['recall_at_k'] = data_scored['response'].cumsum() / data_scored['response'].sum()\n",
    "    \n",
    "    return data_scored\n",
    "\n",
    "def cross_validation(kfold, modelName, model, data, at_k):\n",
    "    # Number of folds\n",
    "    fold=ms.StratifiedKFold(n_splits = kfold, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Performance variables\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    cv_performance = {}\n",
    "    \n",
    "    for train_cv,val_cv in fold.split(data, data['response']):\n",
    "        \n",
    "        # Separating train and validation dataset for each kfold\n",
    "        # training data\n",
    "        x_train_fold = data.iloc[train_cv]\n",
    "        x_train_fold = x_train_fold[cols_selected]\n",
    "        \n",
    "        y_train_fold = data['response'].iloc[train_cv]\n",
    "        \n",
    "        # validation data\n",
    "        x_val_fold = data.iloc[val_cv]\n",
    "        x_val_fold = x_val_fold[cols_selected]\n",
    "        \n",
    "        y_val_fold = data['response'].iloc[val_cv]\n",
    "        \n",
    "        # fitting the model\n",
    "        model_fitted = model.fit(x_train_fold,y_train_fold)\n",
    "        \n",
    "        # getting the prediction probability\n",
    "        x_val_fold['response'] = y_val_fold\n",
    "        val_scored = prediction_score(model_fitted, x_val_fold)\n",
    "        \n",
    "        # Getting precision and recall at k\n",
    "        precision = val_scored.loc[at_k, 'precision_at_k']\n",
    "        recall = val_scored.loc[at_k, 'recall_at_k']\n",
    "        \n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        \n",
    "    # calculating the mean and std performance of all kfolds\n",
    "    precision_cv = np.round(np.mean(precision_list),4).astype(float)\n",
    "    std_precision_cv = '+/-' + np.round(np.std(precision_list),4).astype(str)\n",
    "    recall_cv = np.round(np.mean(recall_list),4).astype(float)\n",
    "    std_recall_cv = ' +/- ' + np.round(np.std(recall_list),4).astype(str)\n",
    "        \n",
    "    cv_performance[modelName] = [precision_cv, std_precision_cv, recall_cv, std_recall_cv]\n",
    "    model_performance_cv = pd.DataFrame(cv_performance, index=['precision_at_k', 'std_precision', 'recall_at_k', 'std_recall'])\n",
    "\n",
    "    return model_performance_cv\n",
    "\n",
    "def ml_performance( model_name, precision_atK, recall_atK ):\n",
    "    \n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "                          'Precision_at_K': precision_atK,\n",
    "                          'Recall_at_K': recall_atK}, index=[0])\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [18, 8]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container {width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab556ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:52:49.664590Z",
     "start_time": "2023-02-05T21:52:49.604723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82380eb7",
   "metadata": {},
   "source": [
    "## 1 - DATAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c520d31c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:52:52.346460Z",
     "start_time": "2023-02-05T21:52:51.855089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Datas - Windows\n",
    "df = pd.read_csv('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/data/raw/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71cfb62",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1.1 - DATA DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc2588d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:52:52.424461Z",
     "start_time": "2023-02-05T21:52:52.411375Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 381109\n",
      "Number of Cols: 12\n"
     ]
    }
   ],
   "source": [
    "# Data Dimensions\n",
    "print( 'Number of Rows: {}'.format( df.shape[0] ) )\n",
    "print( 'Number of Cols: {}'.format( df.shape[1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c7ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T22:47:29.165620Z",
     "start_time": "2023-02-04T22:47:29.150737Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Data Types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80118f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T22:47:30.034174Z",
     "start_time": "2023-02-04T22:47:29.979721Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Changing data types\n",
    "df['region_code'] = df['region_code'].astype(object)\n",
    "df['policy_sales_channel'] = df['policy_sales_channel'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4281e02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T22:47:30.760015Z",
     "start_time": "2023-02-04T22:47:30.399922Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check NAN Values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa0687",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1.1 - DATA DESCRIPTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079e9d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T20:07:58.627852Z",
     "start_time": "2023-02-04T20:07:58.196412Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5519b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T20:07:58.799256Z",
     "start_time": "2023-02-04T20:07:58.629729Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95336af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T20:07:59.422185Z",
     "start_time": "2023-02-04T20:07:59.363637Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Select columns where the content is different 0 or 1.\n",
    "num_attributes = df[['age','annual_premium','vintage']]\n",
    "cat_attributes = df[['driving_license','region_code','policy_sales_channel','previously_insured','gender','vehicle_age','vehicle_damage']]\n",
    "target_atribute = df['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e2b7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T20:08:00.738046Z",
     "start_time": "2023-02-04T20:07:59.600883Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_attributes.hist(bins=25, figsize = (10, 5 ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d236678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T20:08:01.094574Z",
     "start_time": "2023-02-04T20:08:00.740897Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Central Tendency - mean, median\n",
    "ct1 = pd.DataFrame( num_attributes.apply( np.mean ) ).T\n",
    "ct2 = pd.DataFrame( num_attributes.apply( np.median ) ).T\n",
    "\n",
    "# Dispersion - std, min, max, range, skew, kurtosis\n",
    "d1 = pd.DataFrame( num_attributes.apply( np.std ) ).T\n",
    "d2 = pd.DataFrame( num_attributes.apply( min ) ).T\n",
    "d3 = pd.DataFrame( num_attributes.apply( max ) ).T\n",
    "d4 = pd.DataFrame( num_attributes.apply( lambda x: x.max() - x.min() ) ).T\n",
    "d5 = pd.DataFrame( num_attributes.apply( lambda x: x.skew() ) ).T\n",
    "d6 = pd.DataFrame( num_attributes.apply( lambda x: x.kurtosis() ) ).T\n",
    "\n",
    "# Concatenar\n",
    "m = pd.concat( [ d2, d3, d4, ct1, ct2, d1, d5, d6 ] ).T.reset_index()\n",
    "m.columns = ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis']\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d63af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T20:08:11.379024Z",
     "start_time": "2023-02-04T20:08:01.097537Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Looking at the distribuition of the following variables.\n",
    "fig, axs = plt.subplots(3, figsize = (8, 10))\n",
    "sns.distplot(df['age'], ax=axs[0], bins=10)\n",
    "sns.distplot(df[df['annual_premium']<100000]['annual_premium'], ax=axs[1])\n",
    "sns.distplot(df['vintage'], ax=axs[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8523d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T20:08:13.675090Z",
     "start_time": "2023-02-04T20:08:11.386111Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, nrows=2, figsize= (15, 8))\n",
    "\n",
    "sns.countplot(x = 'driving_license', palette = 'Set2', data=df, ax=axs[0][0])\n",
    "sns.countplot(x = 'previously_insured', palette = 'Set2', data=df, ax=axs[0][1])\n",
    "sns.countplot(x = 'gender', palette = 'Set2', data=df, ax=axs[0][2])\n",
    "sns.countplot(x = 'vehicle_age', palette = 'Set2', data=df, ax=axs[1][0])\n",
    "sns.countplot(x = 'vehicle_damage', palette = 'Set2', data=df, ax=axs[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83c12d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T20:08:15.597433Z",
     "start_time": "2023-02-04T20:08:13.680625Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize = (15,5))\n",
    "sns.countplot(x='region_code', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d50948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T20:08:18.137397Z",
     "start_time": "2023-02-04T20:08:15.600111Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "policy_1 = df['policy_sales_channel'].value_counts().iloc[0:55]\n",
    "policy_1 = policy_1.reset_index()\n",
    "policy_2 = df['policy_sales_channel'].value_counts().iloc[55:110]\n",
    "policy_2 = policy_2.reset_index()\n",
    "policy_3 = df['policy_sales_channel'].value_counts().iloc[110:156]\n",
    "policy_3 = policy_3.reset_index()\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(15,15))\n",
    "sns.barplot(y='index', x='policy_sales_channel', data=policy_1, ax=axs[0], orient='h', order=policy_1['index'])\n",
    "sns.barplot(y='index', x='policy_sales_channel', data=policy_2, ax=axs[1], orient='h', order=policy_2['index'])\n",
    "sns.barplot(y='index', x='policy_sales_channel', data=policy_3, ax=axs[2], orient='h', order=policy_3['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a7dd3",
   "metadata": {},
   "source": [
    "## 2 - FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7efac598",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:52:57.854348Z",
     "start_time": "2023-02-05T21:52:57.825192Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e97cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:52:58.342085Z",
     "start_time": "2023-02-05T21:52:58.037167Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting vehicle_age column\n",
    "df2['vehicle_age'] = df2['vehicle_age'].apply(lambda x: 1 if (x == '< 1 Year') else 2 if (x == '1-2 Year') else 3)\n",
    "\n",
    "# Fitting vehicle_damage column\n",
    "df2['vehicle_damage'] = df2['vehicle_damage'].apply(lambda x: 1 if (x == 'Yes') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23b4658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:52:58.372689Z",
     "start_time": "2023-02-05T21:52:58.348187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       int64\n",
       "gender                  object\n",
       "age                      int64\n",
       "region_code              int64\n",
       "policy_sales_channel     int64\n",
       "driving_license          int64\n",
       "vehicle_age              int64\n",
       "vehicle_damage           int64\n",
       "previously_insured       int64\n",
       "annual_premium           int64\n",
       "vintage                  int64\n",
       "response                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b0785",
   "metadata": {},
   "source": [
    "### 2.1 - NEW FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9577c940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:53:02.225207Z",
     "start_time": "2023-02-05T21:53:01.732358Z"
    }
   },
   "outputs": [],
   "source": [
    "# median_premium_by_region\n",
    "dict_region_code = df2[['annual_premium', 'region_code']].groupby('region_code').median().to_dict(orient='dict')['annual_premium']\n",
    "df2['median_premium_by_region'] = df2['region_code'].map(dict_region_code)\n",
    "\n",
    "# moda policy sales chanel por idade\n",
    "mode_policy_per_age = df2[['age', 'policy_sales_channel']].groupby('age').agg(pd.Series.mode).to_dict(orient='dict')['policy_sales_channel']\n",
    "df2['mode_policy_per_age'] = df2['age'].map(mode_policy_per_age)\n",
    "\n",
    "# Media de carros danificados por idade\n",
    "avg_carros_danificados_idade = df2[['age', 'vehicle_damage']].groupby('age').mean().to_dict(orient='dict')['vehicle_damage']\n",
    "df2['avg_vehicle_damage_per_age'] = df2['age'].map(avg_carros_danificados_idade)\n",
    "\n",
    "# Media de carros danificados por regiao\n",
    "avg_carros_danificados_regiao = df2[['region_code', 'vehicle_damage']].groupby('region_code').mean().to_dict(orient='dict')['vehicle_damage']\n",
    "df2['avg_vehicle_damage_region_code'] = df2['region_code'].map(avg_carros_danificados_regiao)\n",
    "\n",
    "# age_group feature creation\n",
    "df2['age_group'] = df2['age'].apply(lambda x: 1 if (x >= 18 | x < 30 ) else 2 if (x >= 30 | x < 60 ) else 3)\n",
    "\n",
    "# vintage_month feature cration\n",
    "df2['vintage_month'] = round(df2['vintage'] / 31)\n",
    "\n",
    "# day_premium feature creation\n",
    "df2['day_premium'] = df2['annual_premium']/df2['vintage']\n",
    "\n",
    "# age_premium feature cration\n",
    "df2['age_premium'] = df2['annual_premium']/df2['age']\n",
    "\n",
    "# Calculating Median Annual Premium by Region_code\n",
    "premium_rc = df2[['annual_premium', 'region_code']].groupby('region_code').median().to_dict(orient='dict')['annual_premium']\n",
    "df2['region_premium'] = df2['region_code'].map(premium_rc)\n",
    "\n",
    "# Calculating Median Aday_premium per policy_sales_channel\n",
    "day_premium_psc = df2[['day_premium', 'policy_sales_channel']].groupby('policy_sales_channel').mean().to_dict(orient='dict')['day_premium']\n",
    "df2['avg_day_premium_policy'] = df2['policy_sales_channel'].map(day_premium_psc)\n",
    "\n",
    "# avg vintage per age\n",
    "avg_vintage_per_age = df2[['age', 'vintage']].groupby('age').mean().to_dict(orient='dict')['vintage']\n",
    "df2['avg_vintage_age'] = df2['age'].map(avg_vintage_per_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05338a2e",
   "metadata": {},
   "source": [
    "## 3 - DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "883783bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:53:09.198507Z",
     "start_time": "2023-02-05T21:53:09.148819Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f56c24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T01:01:26.687072Z",
     "start_time": "2023-02-05T01:01:26.665227Z"
    }
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a69264e",
   "metadata": {},
   "source": [
    "## 4 - EXPLORATORY DATA ANALYSIS (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "289d64ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T21:53:11.056831Z",
     "start_time": "2023-02-05T21:53:11.024244Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056e2c3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 4.1 - UNIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecfce0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T17:56:22.882679Z",
     "start_time": "2023-02-04T17:56:22.856765Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b015ba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T17:59:03.762894Z",
     "start_time": "2023-02-04T17:58:36.635672Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 25))\n",
    "plt.suptitle(\"Analysis Of Variable Response\",fontweight=\"bold\", fontsize=20)\n",
    "\n",
    "plt.subplot(6,2,1)\n",
    "sns.countplot(x = 'response', hue = 'gender', palette = 'Set2', data = df4)\n",
    "\n",
    "plt.subplot(6,2,2)\n",
    "sns.countplot(x = 'response', hue = 'previously_insured', palette = 'Set2', data = df4)\n",
    "\n",
    "plt.subplot(6,2,3)\n",
    "sns.countplot(x = 'response', hue = 'vehicle_age', palette = 'Set2', data = df4)\n",
    "\n",
    "plt.subplot(6,2,4)\n",
    "sns.countplot(x = 'response', hue = 'vehicle_damage', palette = 'Set2', data = df4)\n",
    "\n",
    "plt.subplot(6,2,5)\n",
    "sns.countplot(x = 'response', hue = 'driving_license', palette = 'Set2', data = df4)\n",
    "\n",
    "plt.subplot(6,2,6)\n",
    "sns.countplot(x='response', hue = 'age_group', palette = 'Set2', data=df4)\n",
    "\n",
    "plt.subplot(6,2,7)\n",
    "sns.kdeplot(x='age', hue='response', palette = 'Set2', shade=True, data=df4)\n",
    "\n",
    "plt.subplot(6,2,8)\n",
    "sns.kdeplot(x='annual_premium', hue='response', palette = 'Set2', shade=True, data=df4)\n",
    "\n",
    "plt.subplot(6,2,9)\n",
    "sns.kdeplot(x='day_premium', hue='response', palette = 'Set2', shade=True, data=df4)\n",
    "\n",
    "plt.subplot(6,2,10)\n",
    "sns.kdeplot(x='age_premium', hue='response', palette = 'Set2', shade=True, data=df4)\n",
    "\n",
    "plt.subplot(6,2,11)\n",
    "sns.kdeplot(x='vintage', hue='response', palette = 'Set2', shade=True, data=df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20a476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:09.441174Z",
     "start_time": "2023-02-04T18:01:04.067482Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 'policy_sales_channel'\n",
    "\n",
    "# set the figure size\n",
    "plt.figure(figsize=(25, 10))\n",
    "\n",
    "# from raw value to percentage\n",
    "total = df4.groupby('policy_sales_channel')['id'].count().reset_index()\n",
    "response_1 = df4.loc[df4.response == 1 ].groupby('policy_sales_channel')['id'].count().reset_index()\n",
    "response_0 = df4.loc[df4.response == 0 ].groupby('policy_sales_channel')['response'].sum().reset_index()\n",
    "resp = pd.merge(response_1, response_0, how = 'outer', on = 'policy_sales_channel')\n",
    "resp['id'] = resp['id'].fillna(0)\n",
    "resp = resp.sort_values(by='policy_sales_channel')\n",
    "resp['id'] = [i / j * 100 for i,j in zip(resp['id'], total['id'])]\n",
    "total['id'] = [i / j * 100 for i,j in zip(total['id'], total['id'])]\n",
    "\n",
    "# bar chart 1 -> top bars (group of 'smoker=No')\n",
    "bar1 = sns.barplot(x=\"policy_sales_channel\",  y=\"id\", data=total, color='darkblue')\n",
    "\n",
    "# bar chart 2 -> bottom bars (group of 'smoker=Yes')\n",
    "bar2 = sns.barplot(x=\"policy_sales_channel\", y=\"id\", data=resp, color='lightblue')\n",
    "\n",
    "# add legend\n",
    "plt.xticks(rotation=90)\n",
    "top_bar = mpatches.Patch(color='darkblue', label='response = No')\n",
    "bottom_bar = mpatches.Patch(color='lightblue', label='response = Yes')\n",
    "plt.legend(handles=[top_bar, bottom_bar])\n",
    "\n",
    "# show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd946a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 4.2 - BIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3ca58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:09.549586Z",
     "start_time": "2023-02-04T18:01:09.446800Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#1.The interest on purchase the vehicle insurance is greater for customers that damaged their vehicle before and doesn't have insurance. (FALSE)\n",
    "d1 = df2[( df2['previously_insured'] == 0) & (df2['vehicle_damage'] == 1)]\n",
    "\n",
    "ax1 = d1[['response','id']].groupby('response').count().reset_index()\n",
    "ax1['percentage'] = round(ax1['id'] / d1['id'].count()*100)\n",
    "ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba18b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:09.656530Z",
     "start_time": "2023-02-04T18:01:09.553265Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 2. The interest on purchase the vehicle insurance is greater for woman than men. (FALSE)\n",
    "aux2 = pd.crosstab(df2['gender'], df2['response'])\n",
    "aux2['percentage'] = aux2[1]/(aux2[0]+aux2[1])\n",
    "aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7cea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:10.263596Z",
     "start_time": "2023-02-04T18:01:09.661565Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 3. The interest on purchase vehicle insurance is greater for vintage customers( 7 months or more )\n",
    "aux3 = df2[df2['vintage_month'] >= 7 ][['id','response']]\n",
    "aux4 = df2[df2['vintage_month'] < 7 ][['id','response']]\n",
    "\n",
    "fix, axs = plt.subplots(ncols = 2, figsize = (15,4))\n",
    "sns.countplot(x = aux3['response'], ax=axs[0]).set_title('Vintage Customer: 7 months or more')\n",
    "sns.countplot(x = aux4['response'], ax=axs[1]).set_title('Vintage Customer: 7 months or less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093de556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:10.309944Z",
     "start_time": "2023-02-04T18:01:10.267531Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux18 = aux3[['response','id']].groupby('response').count().reset_index()\n",
    "aux18['percentage'] = round( aux18['id'] / aux3.shape[0] * 100 )\n",
    "aux18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f96e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:10.340906Z",
     "start_time": "2023-02-04T18:01:10.311463Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux19 = aux4[['response','id']].groupby('response').count().reset_index()\n",
    "aux19['percentage'] = round( aux19['id'] / aux4.shape[0] * 100 )\n",
    "aux19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb96e3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:10.888815Z",
     "start_time": "2023-02-04T18:01:10.343376Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 4. The interest on purchase the vehicle insurance is greater for customers that spend less than 30k for annual premium.\n",
    "aux5 = df2[df2['annual_premium'] > 30000][['id','response']]\n",
    "aux6 = df2[df2['annual_premium'] <= 30000][['id','response']]\n",
    "\n",
    "fix, axs = plt.subplots(ncols = 2, figsize = (15,4))\n",
    "sns.countplot(x = aux5['response'], ax=axs[0]).set_title('Annual Premium: 30k or more')\n",
    "sns.countplot(x = aux6['response'], ax=axs[1]).set_title('Annual Premium: 30k or less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac81428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:17.645586Z",
     "start_time": "2023-02-04T18:01:17.613478Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux16 = aux5[['response','id']].groupby('response').count().reset_index()\n",
    "aux16['percentage'] = round( aux16['id'] / aux5.shape[0] * 100 )\n",
    "aux16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29533831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:17.971668Z",
     "start_time": "2023-02-04T18:01:17.934919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux17 = aux6[['response','id']].groupby('response').count().reset_index()\n",
    "aux17['percentage'] = round( aux17['id'] / aux6.shape[0] * 100 )\n",
    "aux17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbea2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:18.563841Z",
     "start_time": "2023-02-04T18:01:18.151383Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 5. The interest on purchase the vehicle insurance is greater for young customers.(Between 18 and 30 years old.)\n",
    "ax7 = sns.countplot(x = df2['response'], hue=df2['age_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606775b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:18.626400Z",
     "start_time": "2023-02-04T18:01:18.567025Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux8 = pd.crosstab(df2['age_group'], df2['response'])\n",
    "aux8['percentage'] = aux8[1]/(aux8[0]+aux8[1])\n",
    "aux8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3171df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:18.721811Z",
     "start_time": "2023-02-04T18:01:18.629320Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 6. The interest on purchase the vehicle insurance is greater for customers that have driver license.\n",
    "aux9 = pd.crosstab(df2['driving_license'], df2['response'])\n",
    "aux9['percentage'] = round(aux9[1]/(aux9[0]+aux9[1])*100)\n",
    "aux9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73549c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:18.800684Z",
     "start_time": "2023-02-04T18:01:18.726379Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 7. The interest on purchase the vehicle insurance is greater for customers that have new cars.\n",
    "aux10 = pd.crosstab(df2['vehicle_age'], df2['response'])\n",
    "aux10['percentage'] = round(aux10[1]/(aux10[0]+aux10[1])*100)\n",
    "aux10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36101afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:18.970576Z",
     "start_time": "2023-02-04T18:01:18.887631Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 8. The interest on purchase the vehicle insurance is greater for customers that have new cars and have damaged their vehicles.\n",
    "aux11 = df2[(df2['vehicle_damage'] == 1 )]\n",
    "aux12 = pd.crosstab(aux11['vehicle_age'], aux11['response'])\n",
    "aux12['percentage'] = round(aux12[1]/(aux12[0]+aux12[1])*100)\n",
    "aux12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5a5d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:19.203352Z",
     "start_time": "2023-02-04T18:01:19.075280Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 9. The interest on purchase the vehicle insurance is greater for elderly women.\n",
    "aux13 = df2[(df2['gender'] == 'Female')]\n",
    "aux14 = pd.crosstab(aux13['age_group'], aux13['response'])\n",
    "aux14['percentage'] = round(aux14[1]/(aux14[0]+aux14[1])*100)\n",
    "aux14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab602a47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:19.326769Z",
     "start_time": "2023-02-04T18:01:19.253417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 10. The interest on purchase the vehicle insurance is lower for customers that are already insured.\n",
    "aux15 = pd.crosstab(df2['previously_insured'], df2['response'])\n",
    "aux15['percentage'] = round(aux15[1]/(aux15[0]+aux15[1])*100)\n",
    "aux15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d10796",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Hypothesis Validation**\n",
    "\n",
    "1. The interest on purchase the vehicle insurance is greater for customers that damaged their vehicle before and doesn't have insurance.\n",
    "    **False, of the customers that damaged their car and doesn't have insurance, only 25% show interest in acquire vehicle insurance.**\n",
    "\n",
    "2. The interest on purchase the vehicle insurance is greater for woman than men.\n",
    "    **False, only 10% of women show interest in acquire vehicle insurance, whereas 13% of the men show interest on acquire vehicle insurance.**\n",
    "\n",
    "3. The interest on purchase vehicle insurance is greater for vintage customers ( 7 months or more ).\n",
    "    **False, the period that customers are on the company doensn't show influency on interest in buying vehicle insurance.**\n",
    "\n",
    "4. The interest on purchase the vehicle insurance is greater for young customers.(Between 18 and 30 years old.)\n",
    "    **False, customers that spend more than 30k yearly show greter interest on purchase vehicle insurance.**\n",
    "\n",
    "5. The interest on purchase the vehicle insurance is greater for young customers.(Between 18 and 30 years old.)\n",
    "    **False, adults and elderlies show greater interest on buying vehicle insurance.**\n",
    "\n",
    "6. The interest on purchase the vehicle insurance is greater for customers that have driver license.\n",
    "    **True, arround 12% of customers that hold a driving license show interest in buying the vehicle insurance.**\n",
    "\n",
    "7. The interest on purchase the vehicle insurance is greater for customers that have new cars.\n",
    "    **False, the interest is greater for customers that own an old car.**\n",
    "\n",
    "8. The interest on purchase the vehicle insurance is greater for customers that have new cars and have damaged their vehicles.\n",
    "    **False, of the customers who damaged their car, the ones that own a old car show greater interest in buying the vehicle insurance (29%), followed by customers that own used cars (27%).**\n",
    "\n",
    "9. The interest on purchase the vehicle insurance is greater for elderly women.\n",
    "    **False, adult women show greater interest in buying the vehicle insurance.**\n",
    "\n",
    "10. The interest on purchase the vehicle insurance is lower for customers that are already insured.\n",
    "    **True, less than 1% of customers already insured show interest on purchase the vehicle insurance.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90475f72",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 4.3 - MULTIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da86da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T20:49:24.136395Z",
     "start_time": "2023-02-04T20:49:21.215366Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correlation = df2.corr().round(2)\n",
    "plt.figure(figsize = (14,7))\n",
    "sns.heatmap(correlation, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550169f4",
   "metadata": {},
   "source": [
    "## 5 - DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05334944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T22:09:47.631941Z",
     "start_time": "2023-02-05T22:09:47.589668Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443cc23d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T09:27:00.865574Z",
     "start_time": "2023-02-04T09:27:00.860160Z"
    }
   },
   "source": [
    "### 5.1 - SPLIT DATASET INTO TRAINING AND VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7dc04b50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T22:10:52.969766Z",
     "start_time": "2023-02-05T22:10:52.756310Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df5.drop( 'response', axis=1 )\n",
    "y = df5['response'].copy()\n",
    "\n",
    "x_training, x_valid, y_training, y_valid = ms.train_test_split( X, y, test_size=0.20 )\n",
    "\n",
    "df6 = pd.concat([ x_training, y_training ], axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7ff8d0",
   "metadata": {},
   "source": [
    "#### 5.1.1 - Balacning Trainig Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85eeb95e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T22:10:53.330514Z",
     "start_time": "2023-02-05T22:10:53.259665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>267583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   response      id\n",
       "0         0  267583\n",
       "1         1   37304"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6[['id','response']].groupby('response').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "964ba507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T22:11:04.034504Z",
     "start_time": "2023-02-05T22:11:03.960998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74608, 23)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_interested=df6[df6['response'] == 1]\n",
    "interested=df6[df6['response'] == 0][:37304]\n",
    "df=pd.concat([non_interested,interested])\n",
    "df7 = df.sample(frac=1,random_state=42)\n",
    "df7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f717496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T22:11:08.046349Z",
     "start_time": "2023-02-05T22:11:08.029097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   response     id\n",
       "0         0  37304\n",
       "1         1  37304"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7[['id','response']].groupby('response').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31ffbf01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T22:11:10.810253Z",
     "start_time": "2023-02-05T22:11:10.782199Z"
    }
   },
   "outputs": [],
   "source": [
    "x_training = df7.drop( 'response', axis=1 )\n",
    "y_training = df7['response'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ba871e23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T22:22:59.362718Z",
     "start_time": "2023-02-05T22:22:59.344929Z"
    }
   },
   "outputs": [],
   "source": [
    "df8 = df7.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c188c",
   "metadata": {},
   "source": [
    "### 5.2 - STANDARDIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ef6f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T01:02:07.122154Z",
     "start_time": "2023-02-05T01:02:07.060717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subtrai-se a media e divide-se pelo desvio padrao\n",
    "ss_ap = pp.StandardScaler()\n",
    "ss_ag = pp.StandardScaler()\n",
    "ss_dp = pp.StandardScaler()\n",
    "ss_dpp = pp.StandardScaler()\n",
    "ss_mp = pp.StandardScaler()\n",
    "ss_rp = pp.StandardScaler()\n",
    "\n",
    "# annual premium\n",
    "df8['annual_premium'] = ss_ap.fit_transform( df8[['annual_premium']].values )\n",
    "pickle.dump(ss_ap, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/annual_premium_scaler.pkl', 'wb'))\n",
    "\n",
    "# age_premium\n",
    "df8['age_premium'] = ss_ag.fit_transform( df8[['age_premium']].values )\n",
    "pickle.dump(ss_ag, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/age_premium_scaler.pkl', 'wb'))\n",
    "\n",
    "# day_premium\n",
    "df8['day_premium'] = ss_dp.fit_transform( df8[['day_premium']].values )\n",
    "pickle.dump(ss_dp, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/day_premium_scaler.pkl', 'wb'))\n",
    "\n",
    "# avg_day_premium_policy\n",
    "df8['avg_day_premium_policy'] = ss_dpp.fit_transform( df8[['avg_day_premium_policy']].values )\n",
    "pickle.dump(ss_dpp, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/avg_day_premium_policy_scaler.pkl', 'wb'))\n",
    "\n",
    "# median_premium_by_region\n",
    "df8['median_premium_by_region'] = ss_mp.fit_transform( df8[['median_premium_by_region']].values )\n",
    "pickle.dump(ss_mp, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/median_premium_by_region_scaler.pkl', 'wb'))\n",
    "\n",
    "# region_premium\n",
    "df8['region_premium'] = ss_rp.fit_transform( df8[['region_premium']].values )\n",
    "pickle.dump(ss_rp, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/region_premium_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42cf00",
   "metadata": {},
   "source": [
    "### 5.3 - REESCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436a08e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T01:02:08.247933Z",
     "start_time": "2023-02-05T01:02:08.185706Z"
    }
   },
   "outputs": [],
   "source": [
    "mms_age = pp.MinMaxScaler()\n",
    "mms_vintage = pp.MinMaxScaler()\n",
    "mms_vintage_age = pp.MinMaxScaler()\n",
    "mms_vm = pp.MinMaxScaler()\n",
    "mms_vd_rc = pp.MinMaxScaler()\n",
    "\n",
    "# Age\n",
    "df8['age'] = mms_age.fit_transform( df8[['age']].values )\n",
    "pickle.dump(mms_age, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/age_scaler.pkl', 'wb'))\n",
    "\n",
    "# Vintage\n",
    "df8['vintage'] = mms_vintage.fit_transform( df8[['vintage']].values )\n",
    "pickle.dump(mms_vintage, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/vintage_scaler.pkl', 'wb'))\n",
    "\n",
    "# avg_vintage_age\n",
    "df8['avg_vintage_age'] = mms_vintage_age.fit_transform( df8[['avg_vintage_age']].values )\n",
    "pickle.dump(mms_vintage_age, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/avg_vintage_age_scaler.pkl', 'wb'))\n",
    "\n",
    "# vintage_month\n",
    "df8['vintage_month'] = mms_vm.fit_transform( df8[['vintage_month']].values )\n",
    "pickle.dump(mms_vintage, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/vintage_scaler.pkl', 'wb'))\n",
    "\n",
    "# avg_vehicle_damage_region_code\n",
    "df8['avg_vehicle_damage_region_code'] = mms_vd_rc.fit_transform( df8[['avg_vehicle_damage_region_code']].values )\n",
    "pickle.dump(mms_vd_rc, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/avg_vehicle_damage_region_code_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a873ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T09:25:06.367009Z",
     "start_time": "2023-02-04T09:25:06.354601Z"
    }
   },
   "source": [
    "### 5.4 - ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a7e1c9ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T22:19:40.119035Z",
     "start_time": "2023-02-05T22:19:40.100953Z"
    }
   },
   "outputs": [],
   "source": [
    "# gender\n",
    "target_encode_gender = df8.groupby( 'gender' )['response'].mean()\n",
    "df8.loc[:, 'gender'] = df8['gender'].map( target_encode_gender )\n",
    "#pickle.dump(target_encode_gender, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/target_encode_gender_scaler.pkl', 'wb'))\n",
    "\n",
    "# region_code - Frequency Encoding / Target Encoding / Weighted Targed Encoding\n",
    "fe_region_code = df8.groupby( 'region_code').size() / len( df8 )\n",
    "df8.loc[:, 'region_code'] = df8['region_code'].map( fe_region_code )\n",
    "#pickle.dump(fe_region_code, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/frequency_encode_region_code_scaler.pkl', 'wb'))\n",
    "\n",
    "# policy_sales_channel - Frequency Encoding / Target Encoding\n",
    "fe_policy_sales_channel = df8.groupby( 'policy_sales_channel' ).size() / len( df8 ) \n",
    "df8.loc[:, 'policy_sales_channel'] = df8['policy_sales_channel'].map( fe_policy_sales_channel )\n",
    "#pickle.dump(fe_policy_sales_channel, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/frequency_encode_policy_sales_scaler.pkl', 'wb'))\n",
    "\n",
    "# vintage_month\n",
    "target_encode_vintage_month = df8.groupby( 'vintage_month' )['response'].mean()\n",
    "df8.loc[:, 'vintage_month'] = df8['vintage_month'].map( target_encode_vintage_month )\n",
    "#pickle.dump(target_encode_vintage_month, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/target_encode_vintage_month_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5b2d5",
   "metadata": {},
   "source": [
    "### 5.5 - VALIDATION PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898347e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T01:02:11.050991Z",
     "start_time": "2023-02-05T01:02:10.899876Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# STANDARDIZATION\n",
    "\n",
    "# annual premium\n",
    "x_valid.loc[:, 'annual_premium'] = ss_ap.transform( x_valid[['annual_premium']].values )\n",
    "\n",
    "# age_premium\n",
    "x_valid.loc[:, 'age_premium'] = ss_ag.transform( x_valid[['age_premium']].values )\n",
    "\n",
    "# day_premium\n",
    "x_valid.loc[:, 'day_premium'] = ss_dp.transform( x_valid[['day_premium']].values )\n",
    "\n",
    "# avg_day_premium_policy\n",
    "x_valid.loc[:,'avg_day_premium_policy'] = ss_dpp.fit_transform( x_valid[['avg_day_premium_policy']].values )\n",
    "\n",
    "# median_premium_by_region\n",
    "x_valid.loc[:,'median_premium_by_region'] = ss_mp.fit_transform( x_valid[['median_premium_by_region']].values )\n",
    "\n",
    "# region_premium\n",
    "x_valid.loc[:,'region_premium'] = ss_rp.fit_transform( x_valid[['region_premium']].values )\n",
    "\n",
    "\n",
    "\n",
    "# REESCALING\n",
    "\n",
    "# age\n",
    "x_valid.loc[:, 'age'] = mms_age.transform( x_valid[['age']].values )\n",
    "\n",
    "# vintage\n",
    "x_valid.loc[:, 'vintage'] = mms_vintage.transform( x_valid[['vintage']].values )\n",
    "\n",
    "# avg_vintage_age\n",
    "x_valid.loc[:,'avg_vintage_age'] = mms_vintage_age.fit_transform( x_valid[['avg_vintage_age']].values )\n",
    "\n",
    "# vintage_month\n",
    "x_valid.loc[:,'vintage_month'] = mms_vm.fit_transform( x_valid[['vintage_month']].values )\n",
    "\n",
    "# avg_vehicle_damage_region_code\n",
    "x_valid.loc[:,'avg_vehicle_damage_region_code'] = mms_vd_rc.fit_transform( x_valid[['avg_vehicle_damage_region_code']].values )\n",
    "\n",
    "\n",
    "\n",
    "# ENCODER\n",
    "\n",
    "# policy sales channel\n",
    "x_valid.loc[:, 'policy_sales_channel'] = x_valid['policy_sales_channel'].map( fe_policy_sales_channel )\n",
    "\n",
    "# region code\n",
    "x_valid.loc[:, 'region_code'] = x_valid.loc[:, 'region_code'].map( fe_region_code )\n",
    "\n",
    "# gender\n",
    "x_valid.loc[:, 'gender'] = x_valid.loc[:, 'gender'].map( target_encode_gender )\n",
    "\n",
    "# vintage_month\n",
    "x_valid.loc[:, 'vintage_month'] = x_valid['vintage_month'].map( target_encode_vintage_month )\n",
    "\n",
    "# FILL NAN VALUES\n",
    "x_valid = x_valid.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff58fed",
   "metadata": {},
   "source": [
    "## 6 - FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173550d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T01:02:14.501916Z",
     "start_time": "2023-02-05T01:02:12.685683Z"
    }
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "forest = en.ExtraTreesClassifier( n_estimators =250, random_state=0, n_jobs=-1 )\n",
    "\n",
    "# data preparation\n",
    "x_train_n = df8.drop( ['id', 'response'], axis=1 )\n",
    "y_train_n  = y_training.values\n",
    "forest.fit( x_train_n, y_train_n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b946fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T01:02:15.003785Z",
     "start_time": "2023-02-05T01:02:14.504121Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0 )\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking \n",
    "print(\"Feature ranking:\")\n",
    "df = pd.DataFrame()\n",
    "for i,j in zip( x_train_n, forest.feature_importances_ ):\n",
    "    aux = pd.DataFrame( {'feature': i, 'importance': j}, index=[0] )\n",
    "    df = pd.concat( [df,aux], axis = 0 )\n",
    "    \n",
    "print( df.sort_values( 'importance', ascending=False ) )\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(x_train_n.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(x_train_n.shape[1]), indices)\n",
    "plt.xlim([-1, x_train_n.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0ce6e",
   "metadata": {},
   "source": [
    "## 7 - FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62994dd9",
   "metadata": {},
   "source": [
    "### 7.1 - MACHINE LEARNING MODEL TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acf4dc",
   "metadata": {},
   "source": [
    "#### 7.1.1 - UNBALANCED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7228449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T21:07:23.800055Z",
     "start_time": "2023-02-04T21:07:23.723730Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_selected = ['day_premium',\n",
    "'vintage',\n",
    "'age_premium',\n",
    "'annual_premium',\n",
    "'vehicle_damage',\n",
    "'vintage_month',\n",
    "'previously_insured',\n",
    "'policy_sales_channel',\n",
    "'region_code',\n",
    "'region_premium',\n",
    "'median_premium_by_region',\n",
    "'avg_day_premium_policy',\n",
    "'age',\n",
    "'avg_vehicle_damage_per_age',\n",
    "'vehicle_age',\n",
    "'avg_vehicle_damage_region_code',\n",
    "'gender',\n",
    "'avg_vintage_age',]\n",
    "\n",
    "x_training = df6[ cols_selected ]\n",
    "x_validation = x_valid[ cols_selected ]\n",
    "y_validation = y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb02967e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T22:08:42.890396Z",
     "start_time": "2023-02-04T22:08:42.879895Z"
    }
   },
   "source": [
    "#### 7.1.2 - BALANCED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab8612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T01:02:54.670385Z",
     "start_time": "2023-02-05T01:02:54.640692Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_selected = ['vehicle_damage',\n",
    "'previously_insured',\n",
    "'vintage',\n",
    "'day_premium',\n",
    "'age_premium',\n",
    "'annual_premium',\n",
    "'vintage_month',\n",
    "'region_code',\n",
    "'avg_vehicle_damage_per_age',\n",
    "'policy_sales_channel',\n",
    "'age',\n",
    "'median_premium_by_region',\n",
    "'region_premium',\n",
    "'avg_day_premium_policy',\n",
    "'vehicle_age',\n",
    "'avg_vehicle_damage_region_code',\n",
    "'avg_vintage_age',\n",
    "'gender']\n",
    "x_training = df8[ cols_selected ]\n",
    "x_validation = x_valid[ cols_selected ]\n",
    "y_validation = y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610eefe4",
   "metadata": {},
   "source": [
    "#### 7.1.1 - XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3107d6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T01:02:57.785533Z",
     "start_time": "2023-02-05T01:02:55.705645Z"
    }
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# model training\n",
    "xgb_model.fit( x_training, y_training )\n",
    "\n",
    "# model prediction - The generalization POWER\n",
    "yhat_xgb = xgb_model.predict_proba( x_validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7f10c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T01:02:58.602398Z",
     "start_time": "2023-02-05T01:02:57.787533Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols= 3, figsize = (18,5))\n",
    "\n",
    "# cumulative gain - Metric for sorting problem\n",
    "skplt.metrics.plot_cumulative_gain(y_validation, yhat_xgb, ax=axs[0],title='Cumulative Gain - XGB');\n",
    "\n",
    "# Lift Curve\n",
    "skplt.metrics.plot_lift_curve(y_validation, yhat_xgb,ax=axs[1],title='Lift Curve - XGB');\n",
    "\n",
    "# Roc Curve\n",
    "skplt.metrics.plot_roc(y_validation, yhat_xgb, ax=axs[2], title='ROC-Curve - XGB');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2755c6b",
   "metadata": {},
   "source": [
    "#### 7.1.2 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56b7dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:01:41.522230Z",
     "start_time": "2023-02-05T00:01:39.228388Z"
    }
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "knn_model = nh.KNeighborsClassifier( n_neighbors=8 )\n",
    "\n",
    "# model training\n",
    "knn_model.fit( x_training, y_training )\n",
    "\n",
    "# model prediction - The generalization POWER\n",
    "yhat_knn = knn_model.predict_proba( x_validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c4ca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:01:42.332131Z",
     "start_time": "2023-02-05T00:01:41.524755Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols= 3, figsize = (18,5))\n",
    "\n",
    "# cumulative gain - Metric for sorting problem\n",
    "skplt.metrics.plot_cumulative_gain(y_validation, yhat_knn, ax=axs[0],title='Cumulative Gain - LGBM');\n",
    "\n",
    "# Lift Curve\n",
    "skplt.metrics.plot_lift_curve(y_validation, yhat_knn,ax=axs[1],title='Lift Curve - LGBM');\n",
    "\n",
    "# Roc Curve\n",
    "skplt.metrics.plot_roc(y_validation, yhat_knn, ax=axs[2], title='ROC-Curve - LGBM');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa88ad",
   "metadata": {},
   "source": [
    "#### 7.1.3 - Light gradient Boostin Machine Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91bffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:01:42.709026Z",
     "start_time": "2023-02-05T00:01:42.334873Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "lgbm_model = lgbm.LGBMClassifier( learning_rate=0.09,max_depth=-5,random_state=42 )\n",
    "\n",
    "# Model training\n",
    "model_lgbm = lgbm_model.fit( x_training, y_training )\n",
    "\n",
    "# Model Prediction\n",
    "yhat_lgbm = model_lgbm.predict_proba( x_validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc4939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:01:43.528000Z",
     "start_time": "2023-02-05T00:01:42.712026Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols= 3, figsize = (18,5))\n",
    "\n",
    "# cumulative gain - Metric for sorting problem\n",
    "skplt.metrics.plot_cumulative_gain(y_validation, yhat_lgbm, ax=axs[0],title='Cumulative Gain - LGBM');\n",
    "\n",
    "# Lift Curve\n",
    "skplt.metrics.plot_lift_curve(y_validation, yhat_lgbm,ax=axs[1],title='Lift Curve - LGBM');\n",
    "\n",
    "# Roc Curve\n",
    "skplt.metrics.plot_roc(y_validation, yhat_lgbm, ax=axs[2], title='ROC-Curve - LGBM');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2bcf46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:01:48.569357Z",
     "start_time": "2023-02-05T00:01:48.225088Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "lgbm_model = lgbm.LGBMClassifier( learning_rate=0.09,max_depth=-5,random_state=42 )\n",
    "\n",
    "# Model training\n",
    "model_lgbm = lgbm_model.fit( x_training, y_training )\n",
    "\n",
    "# Model Prediction\n",
    "yhat_lgbm1 = model_lgbm.predict( x_validation )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebee327",
   "metadata": {},
   "source": [
    "## 8 - MODEL PERFORMANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef8218b",
   "metadata": {},
   "source": [
    "### 8.1 - XGB MODEL PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ccef64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T01:03:03.006786Z",
     "start_time": "2023-02-05T01:03:02.926859Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy Data\n",
    "df8_unbalanced = x_valid.copy()\n",
    "df8_unbalanced['response'] = y_valid.copy()\n",
    "\n",
    "# Propensity score\n",
    "df8_unbalanced['score'] = yhat_xgb[:,1].tolist()\n",
    "\n",
    "# sorted clients by score\n",
    "df8_unbalanced = df8_unbalanced.sort_values( 'score', ascending=False )\n",
    "\n",
    "# Compute precision at K\n",
    "precision_atK = precision_at_k(df8_unbalanced, k=14000 )\n",
    "\n",
    "# Compute precision at K\n",
    "recall_atK = recall_at_k(df8_unbalanced, k=14000 )\n",
    "\n",
    "xgb_performance = ml_performance('XGB Model', precision_atK, recall_atK )\n",
    "xgb_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26618e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T17:36:04.884987Z",
     "start_time": "2023-02-04T17:36:04.868607Z"
    }
   },
   "source": [
    "### 8.2 - KNN MODEL PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6408ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:01:56.700744Z",
     "start_time": "2023-02-05T00:01:56.632993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy Data\n",
    "df8_unbalanced = x_valid.copy()\n",
    "df8_unbalanced['response'] = y_valid.copy()\n",
    "\n",
    "# Propensity score\n",
    "df8_unbalanced['score'] = yhat_knn[:,1].tolist()\n",
    "\n",
    "# sorted clients by score\n",
    "df8_unbalanced = df8_unbalanced.sort_values( 'score', ascending=False )\n",
    "\n",
    "# Compute precision at K\n",
    "precision_atK = precision_at_k(df8_unbalanced, k=14000 )\n",
    "\n",
    "# Compute precision at K\n",
    "recall_atK = recall_at_k(df8_unbalanced, k=14000 )\n",
    "\n",
    "KNN_performance = ml_performance('KNN_Model', precision_atK, recall_atK )\n",
    "KNN_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a210e9d",
   "metadata": {},
   "source": [
    "### 8.3 - LGBM MODEL PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7ce56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:01:58.074040Z",
     "start_time": "2023-02-05T00:01:58.005674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy Data\n",
    "df8_unbalanced = x_valid.copy()\n",
    "df8_unbalanced['response'] = y_valid.copy()\n",
    "\n",
    "# Propensity score\n",
    "df8_unbalanced['score'] = yhat_lgbm[:,1].tolist()\n",
    "\n",
    "# sorted clients by score\n",
    "df8_unbalanced = df8_unbalanced.sort_values( 'score', ascending=False )\n",
    "\n",
    "# Compute precision at K\n",
    "precision_atK = precision_at_k(df8_unbalanced, k=14000 )\n",
    "\n",
    "# Compute precision at K\n",
    "recall_atK = recall_at_k(df8_unbalanced, k=14000 )\n",
    "\n",
    "lgbm_performance = ml_performance('LGBM Model', precision_atK, recall_atK )\n",
    "lgbm_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c89fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_valid,yhat_lgbm1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61b11d",
   "metadata": {},
   "source": [
    "### 8.3 - PERFORMANCE FOR ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b69c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:03:10.889752Z",
     "start_time": "2023-02-05T00:03:10.874704Z"
    }
   },
   "outputs": [],
   "source": [
    "model_performance = pd.concat( [xgb_performance, KNN_performance, lgbm_performance] )\n",
    "model_performance.sort_values('Precision_at_K', ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a742dc95",
   "metadata": {},
   "source": [
    "## 9 - HYPERPARAMETER FINE TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bf176",
   "metadata": {},
   "source": [
    "### 9.1 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e957f06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:03:21.399979Z",
     "start_time": "2023-02-05T00:03:21.360267Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenation train and validation dataset to use in cross-validation\n",
    "df_cv = x_training.copy()\n",
    "df_cv['response'] = y_training\n",
    "\n",
    "df_aux = x_valid.copy()\n",
    "df_aux['response'] = y_valid\n",
    "\n",
    "df_cc = pd.concat([df_cv, df_aux])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8526249a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:03:48.115692Z",
     "start_time": "2023-02-05T00:03:21.705747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictioary with models instantiated\n",
    "models = { 'KNN': knn_model,\n",
    "           'XGB Model': xgb_model,\n",
    "           'lgbm Model': lgbm_model}\n",
    "\n",
    "# Cross-validated models performance\n",
    "model_performance = pd.DataFrame()\n",
    "\n",
    "for key in models.keys():\n",
    "    performance_cv = cross_validation(5, key, models[key], df_cc, 14000)\n",
    "    model_performance = pd.concat([model_performance, performance_cv], axis=1)\n",
    "\n",
    "model_performance.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b77a0",
   "metadata": {},
   "source": [
    "### 9.3 - LGBM Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c279ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:03:48.146340Z",
     "start_time": "2023-02-05T00:03:48.117692Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df8.drop( 'response', axis=1 ).reset_index(drop=True)\n",
    "y = df8[['response']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c136355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:03:48.161859Z",
     "start_time": "2023-02-05T00:03:48.148340Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        #\"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = lgbm.LGBMClassifier(objective=\"binary\", **param_grid)\n",
    "        model.fit( X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=\"auc\", early_stopping_rounds=100, callbacks=[LightGBMPruningCallback(trial, metric='auc')],  # Add a pruning callback \n",
    "                 )\n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_scores[idx] = log_loss(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c3062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:04:23.670492Z",
     "start_time": "2023-02-05T00:03:48.164377Z"
    }
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize' , study_name=\"LGBM Classifier\")\n",
    "func = lambda trial: objective(trial, X, y)\n",
    "study.optimize(func, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cddfcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:04:23.686322Z",
     "start_time": "2023-02-05T00:04:23.671998Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14102895",
   "metadata": {},
   "source": [
    "#### 9.3.1 - LGBM After Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c43d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:06:54.159983Z",
     "start_time": "2023-02-05T00:06:54.140402Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "'n_estimators': 10000,\n",
    "'learning_rate': 0.023388717892026647,\n",
    "'num_leaves': 2400,\n",
    "'max_depth': 3,\n",
    "'min_data_in_leaf': 8100,\n",
    "'lambda_l1': 75,\n",
    "'lambda_l2': 60,\n",
    "'min_gain_to_split': 6.871322598066593,\n",
    "'bagging_fraction': 0.6000000000000001,\n",
    "'bagging_freq': 1,\n",
    "'feature_fraction': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438f7eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:07:04.412093Z",
     "start_time": "2023-02-05T00:06:56.601202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "lgbm_model = lgbm.LGBMClassifier(**params )\n",
    "\n",
    "# Model Training\n",
    "model_lgbm = lgbm_model.fit( x_training, y_training )\n",
    "\n",
    "# Model Prediction\n",
    "yhat_lgbm = model_lgbm.predict_proba( x_validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8b3d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:07:08.319470Z",
     "start_time": "2023-02-05T00:07:04.414211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "lgbm_model = lgbm.LGBMClassifier(n_estimators=10000, learning_rate=0.20184012746410188,is_unbalance=True, objective='binary', metric='auc', boost_from_average=False,\n",
    "                                 num_leaves=20, max_depth=12, min_data_in_leaf=6500, lambda_l1=25, lambda_l2=90, min_gain_to_split=0.044158872935457116,\n",
    "                                 bagging_fraction=0.9, bagging_freq=1, feature_fraction=0.9 )\n",
    "\n",
    "# Model Training\n",
    "model_lgbm = lgbm_model.fit( x_training, y_training )\n",
    "\n",
    "# Model Prediction\n",
    "yhat_lgbm = model_lgbm.predict_proba( x_validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b21ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:07:11.640641Z",
     "start_time": "2023-02-05T00:07:10.752780Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols= 3, figsize = (18,5))\n",
    "\n",
    "# cumulative gain - Metric for sorting problem\n",
    "skplt.metrics.plot_cumulative_gain(y_validation, yhat_lgbm, ax=axs[0],title='Cumulative Gain - LGBM');\n",
    "\n",
    "# Lift Curve\n",
    "skplt.metrics.plot_lift_curve(y_validation, yhat_lgbm,ax=axs[1],title='Lift Curve - LGBM');\n",
    "\n",
    "# Roc Curve\n",
    "skplt.metrics.plot_roc(y_validation, yhat_lgbm, ax=axs[2], title='ROC-Curve - LGBM');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384d768",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:07:17.232503Z",
     "start_time": "2023-02-05T00:07:17.156761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy Data\n",
    "df8_unbalanced = x_valid.copy()\n",
    "df8_unbalanced['response'] = y_valid.copy()\n",
    "\n",
    "# Propensity score\n",
    "df8_unbalanced['score'] = yhat_lgbm[:,1].tolist()\n",
    "\n",
    "# sorted clients by score\n",
    "df8_unbalanced = df8_unbalanced.sort_values( 'score', ascending=False )\n",
    "\n",
    "# Compute precision at K\n",
    "precision_atK = precision_at_k(df8_unbalanced, k=14000 )\n",
    "\n",
    "# Compute precision at K\n",
    "recall_atK = recall_at_k(df8_unbalanced, k=14000 )\n",
    "\n",
    "lgbm_performance_cv = ml_performance('LGBM Model', precision_atK, recall_atK )\n",
    "lgbm_performance_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7739b14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T17:56:50.917555Z",
     "start_time": "2023-02-04T17:56:50.917555Z"
    }
   },
   "outputs": [],
   "source": [
    "#pickle.dump(lgbm_model, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/models/lgbm_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c16f37",
   "metadata": {},
   "source": [
    "### 9.4 - XGB FINE TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5f302",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T22:57:28.368306Z",
     "start_time": "2023-02-04T22:57:28.356427Z"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809f48c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T22:57:28.666052Z",
     "start_time": "2023-02-04T22:57:28.656051Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "     'n_estimators': [1000, 1500, 2000, 2500], \n",
    "     'eta': [0.01, 0.03],\n",
    "     'max_depth': [3, 5, 9],\n",
    "     'subsample': [0.1, 0.5, 0.7],\n",
    "     'colsample_bytree': [0.3, 0.7, 0.9],\n",
    "     'min_child_weight':[3, 8, 15] }\n",
    "\n",
    "MAX_EVAL = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9cdca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T22:57:50.865168Z",
     "start_time": "2023-02-04T22:57:29.227033Z"
    }
   },
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame()\n",
    "\n",
    "for i in range( MAX_EVAL ):\n",
    "# choose values for parameters randomly\n",
    "    hp = { k: random.sample(v, 1)[0] for k, v in param.items() }\n",
    "    print( hp )\n",
    "    \n",
    "#    # model\n",
    "    model_xgb = XGBClassifier(colsample_bytree =hp['colsample_bytree'],\n",
    "                               subsample = hp['subsample'],\n",
    "                               objective='binary:logistic', \n",
    "                               n_estimators=hp['n_estimators'], \n",
    "                               max_depth=hp['max_depth'],\n",
    "                               min_child_weight = hp['min_child_weight'],\n",
    "                               eta=hp['eta'])\n",
    "    # performance\n",
    "    result = cross_validation(2, 'xgb classifier', xgb_model, df_cc, 20000)\n",
    "    final_result = pd.concat( [final_result, result] )\n",
    "\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713c3ee",
   "metadata": {},
   "source": [
    "#### 9.4.1 - XGB AFTER TUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997a2b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:25:55.128405Z",
     "start_time": "2023-02-05T00:25:55.035348Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(model_xgb_cv, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/models/xgb_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d5533",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:07:45.510754Z",
     "start_time": "2023-02-05T00:07:27.110138Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGB CROSS VALIDATION\n",
    "\n",
    "# model definition\n",
    "model_xgb_cv = XGBClassifier( colsample_bytree = 0.3,\n",
    "                              subsample = 0.1,\n",
    "                              objective='binary:logistic', \n",
    "                              n_estimators=1500, \n",
    "                              max_depth=9,\n",
    "                              min_child_weight = 3,\n",
    "                              eta= 0.03 )\n",
    "\n",
    "# model training\n",
    "model_xgb_cv.fit( x_training, y_training )\n",
    "\n",
    "# model prediction - The generalization POWER\n",
    "yhat_xgb_cv = model_xgb_cv.predict_proba( x_validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb0cac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:07:45.605557Z",
     "start_time": "2023-02-05T00:07:45.513769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copy Data\n",
    "df8_unbalanced = x_valid.copy()\n",
    "df8_unbalanced['response'] = y_valid.copy()\n",
    "\n",
    "# Propensity score\n",
    "df8_unbalanced['score'] = yhat_xgb_cv[:,1].tolist()\n",
    "\n",
    "# sorted clients by score\n",
    "df8_unbalanced = df8_unbalanced.sort_values( 'score', ascending=False )\n",
    "\n",
    "# Compute precision at K\n",
    "precision_atK = precision_at_k(df8_unbalanced, k=14000 )\n",
    "\n",
    "# Compute precision at K\n",
    "recall_atK = recall_at_k(df8_unbalanced, k=14000 )\n",
    "\n",
    "lgbm_performance_cv = ml_performance('XGB Model', precision_atK, recall_atK )\n",
    "lgbm_performance_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c647c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T00:15:36.693910Z",
     "start_time": "2023-02-05T00:15:36.660693Z"
    }
   },
   "outputs": [],
   "source": [
    "df8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a55409",
   "metadata": {},
   "source": [
    "## 10 - DEPLOYING MODEL TO PRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e92906",
   "metadata": {},
   "source": [
    "### 10.1 - HEALTHINSURANCE CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa080b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import inflection\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "class HealthInsurance:\n",
    "    \n",
    "    def __init__( self ):\n",
    "        self.home_path                                = ''\n",
    "        self.frequency_encode_policy_sales_scaler     = pickle.load( open( self.home_path + 'src/features/frequency_encode_policy_sales_scaler.pkl', 'rb') )\n",
    "        self.frequency_encode_region_code_scaler      = pickle.load( open( self.home_path + 'src/features/frequency_encode_region_code_scaler.pkl', 'rb') )\n",
    "        self.target_encode_gender_scaler              = pickle.load( open( self.home_path + 'src/features/target_encode_gender_scaler.pkl', 'rb') )\n",
    "        self.target_encode_vintage_month_scaler       = pickle.load( open( self.home_path + 'src/features/target_encode_vintage_month_scaler.pkl', 'rb') )\n",
    "        self.age_scaler                               = pickle.load( open( self.home_path + 'src/features/age_scaler.pkl', 'rb') )\n",
    "        self.avg_vehicle_damage_region_code_scaler    = pickle.load( open( self.home_path + 'src/features/age_scaler.pkl', 'rb') )\n",
    "        self.avg_vintage_age_scaler                   = pickle.load( open( self.home_path + 'src/features/avg_vintage_age_scaler.pkl', 'rb') )\n",
    "        self.vintage_scaler                           = pickle.load( open( self.home_path + 'src/features/vintage_scaler.pkl', 'rb') )\n",
    "        self.age_premium_scaler                       = pickle.load( open( self.home_path + 'src/features/age_premium_scaler.pkl', 'rb') )\n",
    "        self.annual_premium_scaler                    = pickle.load( open( self.home_path + 'src/features/age_premium_scaler.pkl', 'rb') )\n",
    "        self.avg_day_premium_policy_scaler            = pickle.load( open( self.home_path + 'src/features/avg_day_premium_policy_scaler.pkl', 'rb') )\n",
    "        self.day_premium_scaler                       = pickle.load( open( self.home_path + 'src/features/day_premium_scaler.pkl', 'rb') )\n",
    "        self.median_premium_by_region_scaler          = pickle.load( open( self.home_path + 'src/features/median_premium_by_region_scaler.pkl', 'rb') )\n",
    "        self.region_premium_scaler                    = pickle.load( open( self.home_path + 'src/features/region_premium_scaler.pkl', 'rb') )\n",
    "    \n",
    "    def data_cleaning( self, df5 ):\n",
    " \n",
    "        ## rename Columns\n",
    "        cols_old = ['id', 'Gender', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
    "\n",
    "        snakecase = lambda x: inflection.underscore( x )\n",
    "        cols_new = list( map( snakecase, cols_old ) )\n",
    "        \n",
    "        # rename\n",
    "        df5.columns = cols_new\n",
    "        \n",
    "        return( df5 )\n",
    "\n",
    "    def feature_engineering( self, df5 ):\n",
    "        \n",
    "        # Fitting vehicle_age column\n",
    "        df5['vehicle_age'] = df5['vehicle_age'].apply(lambda x: 1 if (x == '< 1 Year') else 2 if (x == '1-2 Year') else 3)\n",
    "\n",
    "        # Fitting vehicle_damage column\n",
    "        df5['vehicle_damage'] = df5['vehicle_damage'].apply(lambda x: 1 if (x == 'Yes') else 0)\n",
    "        \n",
    "        # median_premium_by_region\n",
    "        dict_region_code = df5[['annual_premium', 'region_code']].groupby('region_code').median().to_dict(orient='dict')['annual_premium']\n",
    "        df5['median_premium_by_region'] = df5['region_code'].map(dict_region_code)\n",
    "\n",
    "        # moda policy sales chanel por idade\n",
    "        mode_policy_per_age = df5[['age', 'policy_sales_channel']].groupby('age').agg(pd.Series.mode).to_dict(orient='dict')['policy_sales_channel']\n",
    "        df5['mode_policy_per_age'] = df5['age'].map(mode_policy_per_age)\n",
    "\n",
    "        # Media de carros danificados por idade\n",
    "        avg_carros_danificados_idade = df5[['age', 'vehicle_damage']].groupby('age').mean().to_dict(orient='dict')['vehicle_damage']\n",
    "        df5['avg_vehicle_damage_per_age'] = df5['age'].map(avg_carros_danificados_idade)\n",
    "\n",
    "        # Media de carros danificados por regiao\n",
    "        avg_carros_danificados_regiao = df5[['age', 'region_code']].groupby('age').mean().to_dict(orient='dict')['region_code']\n",
    "        df5['avg_vehicle_damage_region_code'] = df5['age'].map(avg_carros_danificados_regiao)\n",
    "\n",
    "        # age_group feature creation\n",
    "        df5['age_group'] = df5['age'].apply(lambda x: 1 if (x >= 18 | x < 30 ) else 2 if (x >= 30 | x < 60 ) else 3)\n",
    "\n",
    "        # vintage_month feature cration\n",
    "        df5['vintage_month'] = round(df5['vintage'] / 31)\n",
    "\n",
    "        # day_premium feature creation\n",
    "        df5['day_premium'] = df5['annual_premium']/df5['vintage']\n",
    "\n",
    "        # age_premium feature cration\n",
    "        df5['age_premium'] = df5['annual_premium']/df5['age']\n",
    "\n",
    "        # Calculating Median Annual Premium by Region_code\n",
    "        premium_rc = df5[['annual_premium', 'region_code']].groupby('region_code').median().to_dict(orient='dict')['annual_premium']\n",
    "        df5['region_premium'] = df5['region_code'].map(premium_rc)\n",
    "\n",
    "        # Calculating Median Aday_premium per policy_sales_channel\n",
    "        day_premium_psc = df5[['day_premium', 'policy_sales_channel']].groupby('policy_sales_channel').mean().to_dict(orient='dict')['day_premium']\n",
    "        df5['avg_day_premium_policy'] = df5['policy_sales_channel'].map(day_premium_psc)\n",
    "\n",
    "        # avg vintage per age\n",
    "        avg_vintage_per_age = df5[['age', 'vintage']].groupby('age').mean().to_dict(orient='dict')['vintage']\n",
    "        df5['avg_vintage_age'] = df5['age'].map(avg_vintage_per_age)\n",
    "        \n",
    "        return( df5 )\n",
    "    \n",
    "    def data_preparation( self, df5 ):\n",
    "              \n",
    "        # STANDARDIZATION\n",
    "\n",
    "        # annual premium\n",
    "        df5['annual_premium'] = self.annual_premium_scaler.transform( df5[['annual_premium']].values )\n",
    "\n",
    "        # age_premium\n",
    "        df5['age_premium'] = self.age_premium_scaler.transform( df5[['age_premium']].values )\n",
    "\n",
    "        # day_premium\n",
    "        df5['day_premium'] = self.day_premium_scaler.transform( df5[['day_premium']].values )\n",
    "\n",
    "        # avg_day_premium_policy\n",
    "        df5['avg_day_premium_policy'] = self.avg_day_premium_policy_scaler.transform( df5[['avg_day_premium_policy']].values )\n",
    "\n",
    "        # median_premium_by_region\n",
    "        df5['median_premium_by_region'] = self.median_premium_by_region_scaler.transform( df5[['median_premium_by_region']].values )\n",
    "\n",
    "        # region_premium\n",
    "        df5['region_premium'] = self.region_premium_scaler.transform( df5[['region_premium']].values )\n",
    "\n",
    "\n",
    "\n",
    "        # REESCALING\n",
    "\n",
    "        # age\n",
    "        df5['age'] = self.age_scaler.transform( df5[['age']].values )\n",
    "\n",
    "        # vintage\n",
    "        df5['vintage'] = self.vintage_scaler.transform( df5[['vintage']].values )\n",
    "\n",
    "        # avg_vintage_age\n",
    "        df5['avg_vintage_age'] = self.avg_vintage_age_scaler.transform( df5[['avg_vintage_age']].values )\n",
    "\n",
    "        # vintage_month\n",
    "        df5['vintage_month'] = self.vintage_scaler.transform( df5[['vintage_month']].values )\n",
    "\n",
    "        # avg_vehicle_damage_region_code\n",
    "        df5['avg_vehicle_damage_region_code'] = self.avg_vehicle_damage_region_code_scaler.transform( df5[['avg_vehicle_damage_region_code']].values )\n",
    "\n",
    "\n",
    "\n",
    "        # ENCODER\n",
    "\n",
    "        # policy sales channel\n",
    "        df5.loc[:, 'policy_sales_channel'] = df5['policy_sales_channel'].map( self.frequency_encode_policy_sales_scaler )\n",
    "\n",
    "        # region code\n",
    "        df5.loc[:, 'region_code'] = df5['region_code'].map( self.frequency_encode_region_code_scaler )\n",
    "\n",
    "        # gender\n",
    "        df5.loc[:, 'gender'] = df5['gender'].map( self.target_encode_gender_scaler )\n",
    "\n",
    "        # vintage_month\n",
    "        df5.loc[:, 'vintage_month'] = df5['vintage_month'].map( self.target_encode_vintage_month_scaler )\n",
    "\n",
    "        # FILL NAN VALUES\n",
    "        x_valid = x_valid.fillna(0)\n",
    "        \n",
    "        # Feature Selection\n",
    "        cols_selected = ['vehicle_damage','previously_insured','vintage','day_premium','age_premium','annual_premium','vintage_month','region_code','avg_vehicle_damage_per_age','policy_sales_channel','age','median_premium_by_region','region_premium',\n",
    "                         'avg_day_premium_policy','vehicle_age','avg_vehicle_damage_region_code','avg_vintage_age','gender']\n",
    "        \n",
    "        return df5[cols_selected]\n",
    "    \n",
    "\n",
    "    def get_prediction( self, model, original_data, test_data ):\n",
    "        # prediction\n",
    "        pred = model.predict_proba( test_data )\n",
    "        \n",
    "        # join pred into the original data\n",
    "        original_data['score'] = pred[:, 1].tolist()\n",
    "        \n",
    "        return original_data.to_json( orient='records', date_format='iso' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce5926",
   "metadata": {},
   "source": [
    "### 10.2 - API HANDLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from flask                           import Flask, request, Response\n",
    "from healthinsurance.healthinsurance import HealthInsurance\n",
    "\n",
    "# logading model\n",
    "model = pickle.load( open( 'src/models/xgb_model.pkl', 'rb' ) )\n",
    "                          \n",
    "# initialize API\n",
    "app = Flask( __name__ )\n",
    "\n",
    "@app.route( '/healthinsurance/predict', methods=['POST'] )\n",
    "def health_insurance_predict():\n",
    "    test_json = request.get_json()\n",
    "    \n",
    "    if test_json: #there is data\n",
    "               \n",
    "        if isinstance( test_json, dict ): # unique example\n",
    "            test_raw = pd.DataFrame( test_json, index=[0] )\n",
    "    \n",
    "        else:\n",
    "            test_raw = pd.DataFrame( test_json, columns=test_json[0].keys() ) # multiple examples\n",
    "            \n",
    "        # Instantiate Rossmann Class\n",
    "        pipeline = HealthInsurance()\n",
    "\n",
    "        # data cleaning\n",
    "        df1 = pipeline.data_cleaning( test_raw )\n",
    "              \n",
    "        # feature engineering\n",
    "        df2 = pipeline.feature_engineering( df1 )\n",
    "\n",
    "        # Data Preparation\n",
    "        df3 = pipeline.data_preparation( df2 )\n",
    "                              \n",
    "        # prediction\n",
    "        df_response = pipeline.get_prediction( model, test_raw, df3 )\n",
    "        \n",
    "        return df_response\n",
    "        \n",
    "    else:\n",
    "        return Response( '{}', status=200, mimetype='application/json' )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run('0.0.0.0')\n",
    "\n",
    "#    port = os.environ.get('PORT', 5000)\n",
    "#    app.run( host='0.0.0.0', port=port )"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
