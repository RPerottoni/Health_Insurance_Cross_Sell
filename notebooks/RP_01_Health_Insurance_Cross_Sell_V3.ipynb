{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba1e0d7",
   "metadata": {},
   "source": [
    "# PA004 - HEALTH INSURANCE CROS-SELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee28ec",
   "metadata": {},
   "source": [
    "Last version of project, according Machine Learning Fundamentals course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96817c",
   "metadata": {},
   "source": [
    "## 0 - IMPORTS AND FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17f6ae08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:21:57.206230Z",
     "start_time": "2023-03-05T12:21:54.289678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perot\\anaconda3\\envs\\health_insurance_venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import optuna\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import lightgbm                                               as lgbm\n",
    "import scikitplot                                             as skplt\n",
    "import matplotlib.patches                                     as mpatches\n",
    "import matplotlib.pyplot                                      as plt\n",
    "import numpy                                                  as np\n",
    "import plotly.express                                         as px\n",
    "import pandas                                                 as pd\n",
    "import seaborn                                                as sns\n",
    "\n",
    "from sklearn                 import preprocessing             as pp\n",
    "from sklearn                 import model_selection           as ms\n",
    "from sklearn                 import neighbors                 as nh\n",
    "from sklearn                 import ensemble                  as en\n",
    "\n",
    "from IPython.core.display    import HTML\n",
    "from IPython.display         import Image\n",
    "from xgboost                 import XGBClassifier\n",
    "from sklearn.metrics         import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from optuna.integration      import LightGBMPruningCallback\n",
    "\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cdef58",
   "metadata": {},
   "source": [
    "### 0.1 - HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc80304a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:21:57.254264Z",
     "start_time": "2023-03-05T12:21:57.208232Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def recall_at_k (data, k=20000):\n",
    "    # Reset Index\n",
    "    data = data.reset_index( drop=True )\n",
    "\n",
    "    # Create Ranking Order\n",
    "    data['ranking'] = data.index + 1\n",
    "\n",
    "    data['recall_at_k'] = data['response'].cumsum() / data['response'].sum()\n",
    "\n",
    "    return data.loc[k, 'recall_at_k'] \n",
    "\n",
    "def precision_at_k (data, k=20000):\n",
    "    # Reset Index\n",
    "    data = data.reset_index( drop=True )\n",
    "\n",
    "    # Create Ranking Order\n",
    "    data['ranking'] = data.index + 1\n",
    "\n",
    "    data['precision_at_k'] = data['response'].cumsum() / data['ranking']\n",
    "\n",
    "    return data.loc[k, 'precision_at_k']\n",
    "\n",
    "def cramer_v( x, y):\n",
    "    cm = pd.crosstab( x, y).values   \n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape    \n",
    "    \n",
    "    chi2 = ss.chi2_contingency( cm )[0]\n",
    "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1) \n",
    "    \n",
    "    return np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) )\n",
    "\n",
    "def prediction_score(model, data):\n",
    "    # Separating train and validation dataset for each kfold\n",
    "    x_train = data.drop(columns=['response'])\n",
    "    y_train = data['response']\n",
    "    \n",
    "    # prediction probability (score)\n",
    "    yhat_proba = model.predict_proba(x_train)[:, 1].tolist()\n",
    "    \n",
    "    # merging score to dataset\n",
    "    data_scored = data.copy()\n",
    "    data_scored['score'] = yhat_proba\n",
    "    \n",
    "    # sort\n",
    "    data_scored = data_scored.sort_values('score', ascending=False)\n",
    "    \n",
    "    # precision and recall\n",
    "    data_scored = data_scored.reset_index(drop=True)\n",
    "    data_scored['n_samples'] = data_scored.index + 1\n",
    "    data_scored['precision_at_k'] = data_scored['response'].cumsum() / data_scored['n_samples']\n",
    "    data_scored['recall_at_k'] = data_scored['response'].cumsum() / data_scored['response'].sum()\n",
    "    \n",
    "    return data_scored\n",
    "\n",
    "def cross_validation(kfold, modelName, model, data, at_k):\n",
    "    # Number of folds\n",
    "    fold=ms.StratifiedKFold(n_splits = kfold, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Performance variables\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    cv_performance = {}\n",
    "    \n",
    "    for train_cv,val_cv in fold.split(data, data['response']):\n",
    "        \n",
    "        # Separating train and validation dataset for each kfold\n",
    "        # training data\n",
    "        x_train_fold = data.iloc[train_cv]\n",
    "        x_train_fold = x_train_fold[cols_selected]\n",
    "        \n",
    "        y_train_fold = data['response'].iloc[train_cv]\n",
    "        \n",
    "        # validation data\n",
    "        x_val_fold = data.iloc[val_cv]\n",
    "        x_val_fold = x_val_fold[cols_selected]\n",
    "        \n",
    "        y_val_fold = data['response'].iloc[val_cv]\n",
    "        \n",
    "        # fitting the model\n",
    "        model_fitted = model.fit(x_train_fold,y_train_fold)\n",
    "        \n",
    "        # getting the prediction probability\n",
    "        x_val_fold['response'] = y_val_fold\n",
    "        val_scored = prediction_score(model_fitted, x_val_fold)\n",
    "        \n",
    "        # Getting precision and recall at k\n",
    "        precision = val_scored.loc[at_k, 'precision_at_k']\n",
    "        recall = val_scored.loc[at_k, 'recall_at_k']\n",
    "        \n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        \n",
    "    # calculating the mean and std performance of all kfolds\n",
    "    precision_cv = np.round(np.mean(precision_list),4).astype(float)\n",
    "    std_precision_cv = '+/-' + np.round(np.std(precision_list),4).astype(str)\n",
    "    recall_cv = np.round(np.mean(recall_list),4).astype(float)\n",
    "    std_recall_cv = ' +/- ' + np.round(np.std(recall_list),4).astype(str)\n",
    "        \n",
    "    cv_performance[modelName] = [precision_cv, std_precision_cv, recall_cv, std_recall_cv]\n",
    "    model_performance_cv = pd.DataFrame(cv_performance, index=['precision_at_k', 'std_precision', 'recall_at_k', 'std_recall'])\n",
    "\n",
    "    return model_performance_cv\n",
    "\n",
    "def ml_performance( model_name, precision_atK, recall_atK ):\n",
    "    \n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "                          'Precision_at_K': precision_atK,\n",
    "                          'Recall_at_K': recall_atK}, index=[0])\n",
    "\n",
    "def data_preparation (df_prep):\n",
    "    # Fitting vehicle_age column\n",
    "    df_prep['vehicle_age'] = df_prep['vehicle_age'].apply(lambda x: 1 if (x == '< 1 Year') else 2 if (x == '1-2 Year') else 3)\n",
    "\n",
    "    # Fitting vehicle_damage column\n",
    "    df_prep['vehicle_damage'] = df_prep['vehicle_damage'].apply(lambda x: 1 if (x == 'Yes') else 0)\n",
    "    \n",
    "    # STANDARDIZATION\n",
    "\n",
    "    # annual premium\n",
    "    df_prep.loc[:, 'annual_premium'] = ss_ap.transform( df_prep[['annual_premium']].values )\n",
    "\n",
    "\n",
    "\n",
    "    # REESCALING\n",
    "\n",
    "    # age\n",
    "    df_prep.loc[:, 'age'] = mms_age.transform( df_prep[['age']].values )\n",
    "\n",
    "    # vintage\n",
    "    df_prep.loc[:, 'vintage'] = mms_vintage.transform( df_prep[['vintage']].values )\n",
    "\n",
    "\n",
    "\n",
    "    # ENCODER\n",
    "\n",
    "    # policy sales channel\n",
    "    df_prep.loc[:, 'policy_sales_channel'] = df_prep['policy_sales_channel'].map( fe_policy_sales_channel )\n",
    "\n",
    "    # region code\n",
    "    df_prep.loc[:, 'region_code'] = df_prep.loc[:, 'region_code'].map( fe_region_code )\n",
    "\n",
    "    # gender\n",
    "    df_prep.loc[:, 'gender'] = df_prep.loc[:, 'gender'].map( fe_gender )\n",
    "\n",
    "    # FILL NAN VALUES\n",
    "    df_prep = df_prep.fillna(0)\n",
    "    \n",
    "    # Feature Selection\n",
    "    cols_selected = ['vintage', 'annual_premium','age','region_code','vehicle_damage','policy_sales_channel','previously_insured','vehicle_age']\n",
    "    \n",
    "    return( df_prep[cols_selected] )\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [18, 8]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container {width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab556ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:21:57.284442Z",
     "start_time": "2023-03-05T12:21:57.256241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82380eb7",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "## 1 - LOADING AND UNDESTANDING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c520d31c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:21:59.400124Z",
     "start_time": "2023-03-05T12:21:59.073953Z"
    }
   },
   "outputs": [],
   "source": [
    "# All data - Linux\n",
    "#df = pd.read_csv('/home/reng/Documents/ds_repos/Projects/Health_Insurance_Cross_Sell/data/raw/data.csv')\n",
    "\n",
    "# All Data - Windows\n",
    "df = pd.read_csv('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/data/raw/data.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495e100",
   "metadata": {},
   "source": [
    "### 1.1 - SPLIT DATASET INTO TRAINING, TEST AND VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6fc3fe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:01.209574Z",
     "start_time": "2023-03-05T12:22:01.054772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x_train: (243909, 11)\n",
      " y_train: (243909,)\n",
      " x_valid: (76222, 11)\n",
      " y_valid: (76222,)\n",
      " x_test: (60978, 11)\n",
      " y_test: (60978,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criando os datasets de treino e validacao\n",
    "X = df.drop( 'response', axis=1 )\n",
    "y = df['response'].copy()\n",
    "x_train, x_valid, y_train, y_valid = ms.train_test_split( X, y, test_size=0.2 )\n",
    "\n",
    "# Criando dataset de teste, a partir do dataset de treino\n",
    "x_train, x_test, y_train, y_test = ms.train_test_split( x_train, y_train, test_size=0.2 )\n",
    "\n",
    "print(f\" x_train: {x_train.shape}\\n y_train: {y_train.shape}\\n x_valid: {x_valid.shape}\\n y_valid: {y_valid.shape}\\n x_test: {x_test.shape}\\n y_test: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71cfb62",
   "metadata": {},
   "source": [
    "### 1.2 - DATA DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66adb583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:30.417008Z",
     "start_time": "2023-03-05T12:22:30.394541Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = x_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc2588d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:32.596011Z",
     "start_time": "2023-03-05T12:22:32.591466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 243909\n",
      "Numfer of Cols: 11\n"
     ]
    }
   ],
   "source": [
    "# Data Dimensions\n",
    "print( 'Number of Rows: {}'.format( df1.shape[0] ) )\n",
    "print( 'Numfer of Cols: {}'.format( df1.shape[1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c7ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:23.564581Z",
     "start_time": "2023-03-02T22:31:23.547585Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Types\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80118f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:23.951391Z",
     "start_time": "2023-03-02T22:31:23.915438Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changing data types\n",
    "df1['region_code'] = df1['region_code'].astype(object)\n",
    "df1['policy_sales_channel'] = df1['policy_sales_channel'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4281e02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:24.343057Z",
     "start_time": "2023-03-02T22:31:24.094162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check NAN Values\n",
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa0687",
   "metadata": {},
   "source": [
    "### 1.3 - DATA DESCRIPTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079e9d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:24.705864Z",
     "start_time": "2023-03-02T22:31:24.445101Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5519b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:24.845002Z",
     "start_time": "2023-03-02T22:31:24.709752Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95336af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:28.239168Z",
     "start_time": "2023-03-02T22:31:24.848905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select columns where the content is different 0 or 1.\n",
    "num_attributes = df1[['age','annual_premium','vintage']]\n",
    "cat_attributes = df1[['driving_license','region_code','policy_sales_channel','previously_insured','gender','vehicle_age','vehicle_damage']]\n",
    "target_atribute = df1['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e2b7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:46.973047Z",
     "start_time": "2023-03-02T22:31:45.755838Z"
    }
   },
   "outputs": [],
   "source": [
    "num_attributes.hist(bins=25, figsize = (10, 5 ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d236678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:47.211105Z",
     "start_time": "2023-03-02T22:31:46.976027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Central Tendency - mean, median\n",
    "ct1 = pd.DataFrame( num_attributes.apply( np.mean ) ).T\n",
    "ct2 = pd.DataFrame( num_attributes.apply( np.median ) ).T\n",
    "\n",
    "# Dispersion - std, min, max, range, skew, kurtosis\n",
    "d1 = pd.DataFrame( num_attributes.apply( np.std ) ).T\n",
    "d2 = pd.DataFrame( num_attributes.apply( min ) ).T\n",
    "d3 = pd.DataFrame( num_attributes.apply( max ) ).T\n",
    "d4 = pd.DataFrame( num_attributes.apply( lambda x: x.max() - x.min() ) ).T\n",
    "d5 = pd.DataFrame( num_attributes.apply( lambda x: x.skew() ) ).T\n",
    "d6 = pd.DataFrame( num_attributes.apply( lambda x: x.kurtosis() ) ).T\n",
    "\n",
    "# Concatenar\n",
    "m = pd.concat( [ d2, d3, d4, ct1, ct2, d1, d5, d6 ] ).T.reset_index()\n",
    "m.columns = ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis']\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d63af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:53.085692Z",
     "start_time": "2023-03-02T22:31:47.214083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Looking at the distribuition of the following variables.\n",
    "fig, axs = plt.subplots(3, figsize = (8, 10))\n",
    "sns.distplot(df1['age'], ax=axs[0], bins=10)\n",
    "sns.distplot(df1[df1['annual_premium']<100000]['annual_premium'], ax=axs[1])\n",
    "sns.distplot(df1['vintage'], ax=axs[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8523d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:57.528289Z",
     "start_time": "2023-03-02T22:31:53.093689Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, nrows=2, figsize= (15, 8))\n",
    "\n",
    "sns.countplot(x = 'driving_license', palette = 'Set2', data=df1, ax=axs[0][0])\n",
    "sns.countplot(x = 'previously_insured', palette = 'Set2', data=df1, ax=axs[0][1])\n",
    "sns.countplot(x = 'gender', palette = 'Set2', data=df1, ax=axs[0][2])\n",
    "sns.countplot(x = 'vehicle_age', fpalette = 'Set2', data=df1, ax=axs[1][0])\n",
    "sns.countplot(x = 'vehicle_damage', palette = 'Set2', data=df1, ax=axs[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83c12d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:57.532190Z",
     "start_time": "2023-03-02T22:31:57.532190Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize = (15,5))\n",
    "sns.countplot(x='region_code', data=df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d50948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:57.537287Z",
     "start_time": "2023-03-02T22:31:57.537287Z"
    }
   },
   "outputs": [],
   "source": [
    "policy_1 = df1['policy_sales_channel'].value_counts().iloc[0:55]\n",
    "policy_1 = policy_1.reset_index()\n",
    "policy_2 = df1['policy_sales_channel'].value_counts().iloc[55:110]\n",
    "policy_2 = policy_2.reset_index()\n",
    "policy_3 = df1['policy_sales_channel'].value_counts().iloc[110:156]\n",
    "policy_3 = policy_3.reset_index()\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(15,15))\n",
    "sns.barplot(y='index', x='policy_sales_channel', data=policy_1, ax=axs[0], orient='h', order=policy_1['index'])\n",
    "sns.barplot(y='index', x='policy_sales_channel', data=policy_2, ax=axs[1], orient='h', order=policy_2['index'])\n",
    "sns.barplot(y='index', x='policy_sales_channel', data=policy_3, ax=axs[2], orient='h', order=policy_3['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a7dd3",
   "metadata": {},
   "source": [
    "## 2 - FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c16f684f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:39.168868Z",
     "start_time": "2023-03-05T12:22:39.146999Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e97cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:39.708704Z",
     "start_time": "2023-03-05T12:22:39.582122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting vehicle_age column\n",
    "df2['vehicle_age'] = df2['vehicle_age'].apply(lambda x: 1 if (x == '< 1 Year') else 2 if (x == '1-2 Year') else 3)\n",
    "\n",
    "# Fitting vehicle_damage column\n",
    "df2['vehicle_damage'] = df2['vehicle_damage'].apply(lambda x: 1 if (x == 'Yes') else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05338a2e",
   "metadata": {},
   "source": [
    "## 3 - DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883783bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:40.862733Z",
     "start_time": "2023-03-05T12:22:40.837736Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a69264e",
   "metadata": {},
   "source": [
    "## 4 - EXPLORATORY DATA ANALYSIS (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "289d64ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:41.554352Z",
     "start_time": "2023-03-05T12:22:41.542331Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056e2c3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 4.1 - UNIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecfce0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:28.426055Z",
     "start_time": "2023-03-02T22:31:28.401102Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b015ba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:31:29.940018Z",
     "start_time": "2023-03-02T22:31:29.563426Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 25))\n",
    "plt.suptitle(\"Analysis Of Variable Response\",fontweight=\"bold\", fontsize=20)\n",
    "\n",
    "plt.subplot(6,2,1)\n",
    "sns.countplot(x = 'response', hue = 'gender', palette = 'Set2', data = df4)\n",
    "\n",
    "plt.subplot(6,2,2)\n",
    "sns.countplot(x = 'response', hue = 'previously_insured', palette = 'Set2', data = df4)\n",
    "\n",
    "plt.subplot(6,2,3)\n",
    "sns.countplot(x = 'response', hue = 'vehicle_age', palette = 'Set2', data = df4)\n",
    "\n",
    "plt.subplot(6,2,4)\n",
    "sns.countplot(x = 'response', hue = 'vehicle_damage', palette = 'Set2', data = df4)\n",
    "\n",
    "plt.subplot(6,2,5)\n",
    "sns.countplot(x = 'response', hue = 'driving_license', palette = 'Set2', data = df4)\n",
    "\n",
    "plt.subplot(6,2,6)\n",
    "sns.countplot(x='response', hue = 'age_group', palette = 'Set2', data=df4)\n",
    "\n",
    "plt.subplot(6,2,7)\n",
    "sns.kdeplot(x='age', hue='response', palette = 'Set2', shade=True, data=df4)\n",
    "\n",
    "plt.subplot(6,2,8)\n",
    "sns.kdeplot(x='annual_premium', hue='response', palette = 'Set2', shade=True, data=df4)\n",
    "\n",
    "plt.subplot(6,2,9)\n",
    "sns.kdeplot(x='day_premium', hue='response', palette = 'Set2', shade=True, data=df4)\n",
    "\n",
    "plt.subplot(6,2,10)\n",
    "sns.kdeplot(x='age_premium', hue='response', palette = 'Set2', shade=True, data=df4)\n",
    "\n",
    "plt.subplot(6,2,11)\n",
    "sns.kdeplot(x='vintage', hue='response', palette = 'Set2', shade=True, data=df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20a476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:09.441174Z",
     "start_time": "2023-02-04T18:01:04.067482Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 'policy_sales_channel'\n",
    "\n",
    "# set the figure size\n",
    "plt.figure(figsize=(25, 10))\n",
    "\n",
    "# from raw value to percentage\n",
    "total = df4.groupby('policy_sales_channel')['id'].count().reset_index()\n",
    "response_1 = df4.loc[df4.response == 1 ].groupby('policy_sales_channel')['id'].count().reset_index()\n",
    "response_0 = df4.loc[df4.response == 0 ].groupby('policy_sales_channel')['response'].sum().reset_index()\n",
    "resp = pd.merge(response_1, response_0, how = 'outer', on = 'policy_sales_channel')\n",
    "resp['id'] = resp['id'].fillna(0)\n",
    "resp = resp.sort_values(by='policy_sales_channel')\n",
    "resp['id'] = [i / j * 100 for i,j in zip(resp['id'], total['id'])]\n",
    "total['id'] = [i / j * 100 for i,j in zip(total['id'], total['id'])]\n",
    "\n",
    "# bar chart 1 -> top bars (group of 'smoker=No')\n",
    "bar1 = sns.barplot(x=\"policy_sales_channel\",  y=\"id\", data=total, color='darkblue')\n",
    "\n",
    "# bar chart 2 -> bottom bars (group of 'smoker=Yes')\n",
    "bar2 = sns.barplot(x=\"policy_sales_channel\", y=\"id\", data=resp, color='lightblue')\n",
    "\n",
    "# add legend\n",
    "plt.xticks(rotation=90)\n",
    "top_bar = mpatches.Patch(color='darkblue', label='response = No')\n",
    "bottom_bar = mpatches.Patch(color='lightblue', label='response = Yes')\n",
    "plt.legend(handles=[top_bar, bottom_bar])\n",
    "\n",
    "# show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd946a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 4.2 - BIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3ca58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:09.549586Z",
     "start_time": "2023-02-04T18:01:09.446800Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#1.The interest on purchase the vehicle insurance is greater for customers that damaged their vehicle before and doesn't have insurance. (FALSE)\n",
    "d1 = df2[( df2['previously_insured'] == 0) & (df2['vehicle_damage'] == 1)]\n",
    "\n",
    "ax1 = d1[['response','id']].groupby('response').count().reset_index()\n",
    "ax1['percentage'] = round(ax1['id'] / d1['id'].count()*100)\n",
    "ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba18b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:09.656530Z",
     "start_time": "2023-02-04T18:01:09.553265Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 2. The interest on purchase the vehicle insurance is greater for woman than men. (FALSE)\n",
    "aux2 = pd.crosstab(df2['gender'], df2['response'])\n",
    "aux2['percentage'] = aux2[1]/(aux2[0]+aux2[1])\n",
    "aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7cea6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:10.263596Z",
     "start_time": "2023-02-04T18:01:09.661565Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 3. The interest on purchase vehicle insurance is greater for vintage customers( 7 months or more )\n",
    "aux3 = df2[df2['vintage_month'] >= 7 ][['id','response']]\n",
    "aux4 = df2[df2['vintage_month'] < 7 ][['id','response']]\n",
    "\n",
    "fix, axs = plt.subplots(ncols = 2, figsize = (15,4))\n",
    "sns.countplot(x = aux3['response'], ax=axs[0]).set_title('Vintage Customer: 7 months or more')\n",
    "sns.countplot(x = aux4['response'], ax=axs[1]).set_title('Vintage Customer: 7 months or less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093de556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:10.309944Z",
     "start_time": "2023-02-04T18:01:10.267531Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux18 = aux3[['response','id']].groupby('response').count().reset_index()\n",
    "aux18['percentage'] = round( aux18['id'] / aux3.shape[0] * 100 )\n",
    "aux18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f96e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:10.340906Z",
     "start_time": "2023-02-04T18:01:10.311463Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux19 = aux4[['response','id']].groupby('response').count().reset_index()\n",
    "aux19['percentage'] = round( aux19['id'] / aux4.shape[0] * 100 )\n",
    "aux19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb96e3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:10.888815Z",
     "start_time": "2023-02-04T18:01:10.343376Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 4. The interest on purchase the vehicle insurance is greater for customers that spend less than 30k for annual premium.\n",
    "aux5 = df2[df2['annual_premium'] > 30000][['id','response']]\n",
    "aux6 = df2[df2['annual_premium'] <= 30000][['id','response']]\n",
    "\n",
    "fix, axs = plt.subplots(ncols = 2, figsize = (15,4))\n",
    "sns.countplot(x = aux5['response'], ax=axs[0]).set_title('Annual Premium: 30k or more')\n",
    "sns.countplot(x = aux6['response'], ax=axs[1]).set_title('Annual Premium: 30k or less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac81428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:17.645586Z",
     "start_time": "2023-02-04T18:01:17.613478Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux16 = aux5[['response','id']].groupby('response').count().reset_index()\n",
    "aux16['percentage'] = round( aux16['id'] / aux5.shape[0] * 100 )\n",
    "aux16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29533831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:17.971668Z",
     "start_time": "2023-02-04T18:01:17.934919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux17 = aux6[['response','id']].groupby('response').count().reset_index()\n",
    "aux17['percentage'] = round( aux17['id'] / aux6.shape[0] * 100 )\n",
    "aux17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbea2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:18.563841Z",
     "start_time": "2023-02-04T18:01:18.151383Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 5. The interest on purchase the vehicle insurance is greater for young customers.(Between 18 and 30 years old.)\n",
    "ax7 = sns.countplot(x = df2['response'], hue=df2['age_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606775b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:18.626400Z",
     "start_time": "2023-02-04T18:01:18.567025Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux8 = pd.crosstab(df2['age_group'], df2['response'])\n",
    "aux8['percentage'] = aux8[1]/(aux8[0]+aux8[1])\n",
    "aux8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3171df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:18.721811Z",
     "start_time": "2023-02-04T18:01:18.629320Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 6. The interest on purchase the vehicle insurance is greater for customers that have driver license.\n",
    "aux9 = pd.crosstab(df2['driving_license'], df2['response'])\n",
    "aux9['percentage'] = round(aux9[1]/(aux9[0]+aux9[1])*100)\n",
    "aux9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73549c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:18.800684Z",
     "start_time": "2023-02-04T18:01:18.726379Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 7. The interest on purchase the vehicle insurance is greater for customers that have new cars.\n",
    "aux10 = pd.crosstab(df2['vehicle_age'], df2['response'])\n",
    "aux10['percentage'] = round(aux10[1]/(aux10[0]+aux10[1])*100)\n",
    "aux10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36101afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:18.970576Z",
     "start_time": "2023-02-04T18:01:18.887631Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 8. The interest on purchase the vehicle insurance is greater for customers that have new cars and have damaged their vehicles.\n",
    "aux11 = df2[(df2['vehicle_damage'] == 1 )]\n",
    "aux12 = pd.crosstab(aux11['vehicle_age'], aux11['response'])\n",
    "aux12['percentage'] = round(aux12[1]/(aux12[0]+aux12[1])*100)\n",
    "aux12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5a5d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:19.203352Z",
     "start_time": "2023-02-04T18:01:19.075280Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 9. The interest on purchase the vehicle insurance is greater for elderly women.\n",
    "aux13 = df2[(df2['gender'] == 'Female')]\n",
    "aux14 = pd.crosstab(aux13['age_group'], aux13['response'])\n",
    "aux14['percentage'] = round(aux14[1]/(aux14[0]+aux14[1])*100)\n",
    "aux14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab602a47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T18:01:19.326769Z",
     "start_time": "2023-02-04T18:01:19.253417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 10. The interest on purchase the vehicle insurance is lower for customers that are already insured.\n",
    "aux15 = pd.crosstab(df2['previously_insured'], df2['response'])\n",
    "aux15['percentage'] = round(aux15[1]/(aux15[0]+aux15[1])*100)\n",
    "aux15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d10796",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Hypothesis Validation**\n",
    "\n",
    "1. The interest on purchase the vehicle insurance is greater for customers that damaged their vehicle before and doesn't have insurance.\n",
    "    **False, of the customers that damaged their car and doesn't have insurance, only 25% show interest in acquire vehicle insurance.**\n",
    "\n",
    "2. The interest on purchase the vehicle insurance is greater for woman than men.\n",
    "    **False, only 10% of women show interest in acquire vehicle insurance, whereas 13% of the men show interest on acquire vehicle insurance.**\n",
    "\n",
    "3. The interest on purchase vehicle insurance is greater for vintage customers ( 7 months or more ).\n",
    "    **False, the period that customers are on the company doensn't show influency on interest in buying vehicle insurance.**\n",
    "\n",
    "4. The interest on purchase the vehicle insurance is greater for young customers.(Between 18 and 30 years old.)\n",
    "    **False, customers that spend more than 30k yearly show greter interest on purchase vehicle insurance.**\n",
    "\n",
    "5. The interest on purchase the vehicle insurance is greater for young customers.(Between 18 and 30 years old.)\n",
    "    **False, adults and elderlies show greater interest on buying vehicle insurance.**\n",
    "\n",
    "6. The interest on purchase the vehicle insurance is greater for customers that have driver license.\n",
    "    **True, arround 12% of customers that hold a driving license show interest in buying the vehicle insurance.**\n",
    "\n",
    "7. The interest on purchase the vehicle insurance is greater for customers that have new cars.\n",
    "    **False, the interest is greater for customers that own an old car.**\n",
    "\n",
    "8. The interest on purchase the vehicle insurance is greater for customers that have new cars and have damaged their vehicles.\n",
    "    **False, of the customers who damaged their car, the ones that own a old car show greater interest in buying the vehicle insurance (29%), followed by customers that own used cars (27%).**\n",
    "\n",
    "9. The interest on purchase the vehicle insurance is greater for elderly women.\n",
    "    **False, adult women show greater interest in buying the vehicle insurance.**\n",
    "\n",
    "10. The interest on purchase the vehicle insurance is lower for customers that are already insured.\n",
    "    **True, less than 1% of customers already insured show interest on purchase the vehicle insurance.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90475f72",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 4.3 - MULTIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da86da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T20:49:24.136395Z",
     "start_time": "2023-02-04T20:49:21.215366Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correlation = df2.corr().round(2)\n",
    "plt.figure(figsize = (14,7))\n",
    "sns.heatmap(correlation, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550169f4",
   "metadata": {},
   "source": [
    "## 5 - DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c122e836",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:44.576659Z",
     "start_time": "2023-03-05T12:22:44.561557Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c188c",
   "metadata": {},
   "source": [
    "### 5.1 - STANDARDIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b784e41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:45.275733Z",
     "start_time": "2023-03-05T12:22:45.242234Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subtrai-se a media e divide-se pelo desvio padrao\n",
    "ss_ap = pp.StandardScaler()\n",
    "\n",
    "# annual premium\n",
    "df5['annual_premium'] = ss_ap.fit_transform( df5[['annual_premium']].values )\n",
    "#pickle.dump(ss_ap, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/annual_premium_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42cf00",
   "metadata": {},
   "source": [
    "### 5.2 - REESCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b436a08e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:46.159168Z",
     "start_time": "2023-03-05T12:22:46.121361Z"
    }
   },
   "outputs": [],
   "source": [
    "mms_age = pp.MinMaxScaler()\n",
    "mms_vintage = pp.MinMaxScaler()\n",
    "\n",
    "# Age\n",
    "df5['age'] = mms_age.fit_transform( df5[['age']].values )\n",
    "#pickle.dump(mms_age, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/age_scaler.pkl', 'wb'))\n",
    "\n",
    "# Vintage\n",
    "df5['vintage'] = mms_vintage.fit_transform( df5[['vintage']].values )\n",
    "#pickle.dump(mms_vintage, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/vintage_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a873ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T09:25:06.367009Z",
     "start_time": "2023-02-04T09:25:06.354601Z"
    }
   },
   "source": [
    "### 5.3 - ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e1c9ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:46.949895Z",
     "start_time": "2023-03-05T12:22:46.856048Z"
    }
   },
   "outputs": [],
   "source": [
    "# Frequency encoder for all columns\n",
    "\n",
    "# gender\n",
    "fe_gender = df5.groupby('gender').size() / len(df5)\n",
    "df5.loc[:, 'gender'] = df5['gender'].map( fe_gender )\n",
    "#pickle.dump(target_encode_gender, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/target_encode_gender_scaler.pkl', 'wb'))\n",
    "\n",
    "# region_code - Frequency Encoding / Target Encoding / Weighted Targed Encoding\n",
    "fe_region_code = df5.groupby( 'region_code').size() / len( df5 )\n",
    "df5.loc[:, 'region_code'] = df5['region_code'].map( fe_region_code )\n",
    "#pickle.dump(fe_region_code, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/frequency_encode_region_code_scaler.pkl', 'wb'))\n",
    "\n",
    "# policy_sales_channel - Frequency Encoding / Target Encoding\n",
    "fe_policy_sales_channel = df5.groupby( 'policy_sales_channel' ).size() / len( df5 ) \n",
    "df5.loc[:, 'policy_sales_channel'] = df5['policy_sales_channel'].map( fe_policy_sales_channel )\n",
    "#pickle.dump(fe_policy_sales_channel, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/features/frequency_encode_policy_sales_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5b2d5",
   "metadata": {},
   "source": [
    "### 5.4 - VALIDATION PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86200fe8",
   "metadata": {},
   "source": [
    "#### 5.5.1 -  Apply Feature Engineering on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95cdc0dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:49.907383Z",
     "start_time": "2023-03-05T12:22:49.848434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting vehicle_age column\n",
    "x_valid['vehicle_age'] = x_valid['vehicle_age'].apply(lambda x: 1 if (x == '< 1 Year') else 2 if (x == '1-2 Year') else 3)\n",
    "\n",
    "# Fitting vehicle_damage column\n",
    "x_valid['vehicle_damage'] = x_valid['vehicle_damage'].apply(lambda x: 1 if (x == 'Yes') else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580ad7c6",
   "metadata": {},
   "source": [
    "#### 5.5.2 -  Apply Data Transformation on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "068a216f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:50.393080Z",
     "start_time": "2023-03-05T12:22:50.320745Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# STANDARDIZATION\n",
    "\n",
    "# annual premium\n",
    "x_valid.loc[:, 'annual_premium'] = ss_ap.transform( x_valid[['annual_premium']].values )\n",
    "\n",
    "\n",
    "\n",
    "# REESCALING\n",
    "\n",
    "# age\n",
    "x_valid.loc[:, 'age'] = mms_age.transform( x_valid[['age']].values )\n",
    "\n",
    "# vintage\n",
    "x_valid.loc[:, 'vintage'] = mms_vintage.transform( x_valid[['vintage']].values )\n",
    "\n",
    "\n",
    "\n",
    "# ENCODER\n",
    "\n",
    "# policy sales channel\n",
    "x_valid.loc[:, 'policy_sales_channel'] = x_valid['policy_sales_channel'].map( fe_policy_sales_channel )\n",
    "\n",
    "# region code\n",
    "x_valid.loc[:, 'region_code'] = x_valid.loc[:, 'region_code'].map( fe_region_code )\n",
    "\n",
    "# gender\n",
    "x_valid.loc[:, 'gender'] = x_valid.loc[:, 'gender'].map( fe_gender )\n",
    "\n",
    "# FILL NAN VALUES\n",
    "x_valid = x_valid.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff58fed",
   "metadata": {},
   "source": [
    "## 6 - FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "908fd545",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:22:51.588097Z",
     "start_time": "2023-03-05T12:22:51.565462Z"
    }
   },
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173550d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T21:53:28.358452Z",
     "start_time": "2023-03-01T21:53:23.768780Z"
    }
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "forest = en.ExtraTreesClassifier( n_estimators =250, random_state=0, n_jobs=-1 )\n",
    "\n",
    "# data preparation\n",
    "df6_n = df6.drop( ['id'], axis=1 )\n",
    "y_train_n  = y_train.values\n",
    "forest.fit( df6_n, y_train_n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b946fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T21:57:13.160935Z",
     "start_time": "2023-03-01T21:57:12.500412Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0 )\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking \n",
    "print(\"Feature ranking:\")\n",
    "df = pd.DataFrame()\n",
    "for i,j in zip( x_train_n, forest.feature_importances_ ):\n",
    "    aux = pd.DataFrame( {'feature': i, 'importance': j}, index=[0] )\n",
    "    df = pd.concat( [df,aux], axis = 0 )\n",
    "    \n",
    "print( df.sort_values( 'importance', ascending=False ) )\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(x_train_n.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(x_train_n.shape[1]), indices)\n",
    "plt.xlim([-1, x_train_n.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7228449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:23:05.470883Z",
     "start_time": "2023-03-05T12:23:05.456905Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_selected = ['vintage', 'annual_premium','age','region_code','vehicle_damage','policy_sales_channel','previously_insured','vehicle_age']\n",
    "\n",
    "x_training = df6[ cols_selected ]\n",
    "x_validation = x_valid[ cols_selected ]\n",
    "y_validation = y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0ce6e",
   "metadata": {},
   "source": [
    "## 7 - ML MODELS TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610eefe4",
   "metadata": {},
   "source": [
    "#### 7.1.1 - XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c40e9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:32:25.810781Z",
     "start_time": "2023-03-02T22:32:25.754012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter \"scale_pos_weight\" definition\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# ESTIMATE SCALE_POS_WEIGHT\n",
    "counter = Counter(y_train)\n",
    "estimate = counter[0]/counter[1]\n",
    "print('Estimate: %.3f' % estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3107d6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:23:12.412648Z",
     "start_time": "2023-03-05T12:23:08.599782Z"
    }
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "xgb_model = XGBClassifier(scale_pos_weight=7.2)\n",
    "\n",
    "# model training\n",
    "xgb_model.fit( x_training, y_train )\n",
    "\n",
    "# model prediction - Check if the model perform well\n",
    "yhat_xgb = xgb_model.predict_proba( x_validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7f10c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T21:05:33.723385Z",
     "start_time": "2023-03-02T21:05:32.156004Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols= 3, figsize = (18,5))\n",
    "\n",
    "# cumulative gain - Metric for sorting problem\n",
    "skplt.metrics.plot_cumulative_gain(y_validation, yhat_xgb, ax=axs[0],title='Cumulative Gain - XGB');\n",
    "\n",
    "# Lift Curve\n",
    "skplt.metrics.plot_lift_curve(y_validation, yhat_xgb,ax=axs[1],title='Lift Curve - XGB');\n",
    "\n",
    "# Roc Curve\n",
    "skplt.metrics.plot_roc(y_validation, yhat_xgb, ax=axs[2], title='ROC-Curve - XGB');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2755c6b",
   "metadata": {},
   "source": [
    "#### 7.1.2 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef56b7dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:23:21.812692Z",
     "start_time": "2023-03-05T12:23:14.958100Z"
    }
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "knn_model = nh.KNeighborsClassifier( n_neighbors=8 )\n",
    "\n",
    "# model training\n",
    "knn_model.fit( x_training, y_train )\n",
    "\n",
    "# model prediction - The generalization POWER\n",
    "yhat_knn = knn_model.predict_proba( x_validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c4ca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T21:05:47.802985Z",
     "start_time": "2023-03-02T21:05:46.029422Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols= 3, figsize = (18,5))\n",
    "\n",
    "# cumulative gain - Metric for sorting problem\n",
    "skplt.metrics.plot_cumulative_gain(y_validation, yhat_knn, ax=axs[0],title='Cumulative Gain - LGBM');\n",
    "\n",
    "# Lift Curve\n",
    "skplt.metrics.plot_lift_curve(y_validation, yhat_knn,ax=axs[1],title='Lift Curve - LGBM');\n",
    "\n",
    "# Roc Curve\n",
    "skplt.metrics.plot_roc(y_validation, yhat_knn, ax=axs[2], title='ROC-Curve - LGBM');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa88ad",
   "metadata": {},
   "source": [
    "#### 7.1.3 - Light gradient Boostin Machine Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f91bffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:23:22.269839Z",
     "start_time": "2023-03-05T12:23:21.814534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "lgbm_model = lgbm.LGBMClassifier( learning_rate=0.09,max_depth=-5,random_state=42 )\n",
    "\n",
    "# Model training\n",
    "model_lgbm = lgbm_model.fit( x_training, y_train )\n",
    "\n",
    "# Model Prediction\n",
    "yhat_lgbm = model_lgbm.predict_proba( x_validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc4939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T21:05:51.059303Z",
     "start_time": "2023-03-02T21:05:49.406832Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols= 3, figsize = (18,5))\n",
    "\n",
    "# cumulative gain - Metric for sorting problem\n",
    "skplt.metrics.plot_cumulative_gain(y_validation, yhat_lgbm, ax=axs[0],title='Cumulative Gain - LGBM');\n",
    "\n",
    "# Lift Curve\n",
    "skplt.metrics.plot_lift_curve(y_validation, yhat_lgbm,ax=axs[1],title='Lift Curve - LGBM');\n",
    "\n",
    "# Roc Curve\n",
    "skplt.metrics.plot_roc(y_validation, yhat_lgbm, ax=axs[2], title='ROC-Curve - LGBM');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fadf405b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T13:35:22.598847Z",
     "start_time": "2023-03-05T13:35:18.716089Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGB treinado e validado com dataset de treinamento\n",
    "# model definition\n",
    "xgb_model = XGBClassifier(scale_pos_weight=7.2)\n",
    "# model training\n",
    "xgb_model.fit( x_training, y_train )\n",
    "# model prediction - Check if the model perform well\n",
    "recall_train_xgb = xgb_model.predict( x_validation )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prerformance\n",
    "recall_train = mt.recall_score(y_train, recall_train_xgb)\n",
    "print('Accuracy over Training:{}'.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa1f5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ebee327",
   "metadata": {},
   "source": [
    "## 8 - MODEL PERFORMANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef8218b",
   "metadata": {},
   "source": [
    "### 8.1 - XGB MODEL PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82d634db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T13:33:13.532842Z",
     "start_time": "2023-03-05T13:33:13.516961Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49ccef64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T13:32:59.550492Z",
     "start_time": "2023-03-05T13:32:59.491128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Precision_at_K</th>\n",
       "      <th>Recall_at_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB Model</td>\n",
       "      <td>0.330833</td>\n",
       "      <td>0.708914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  Precision_at_K  Recall_at_K\n",
       "0  XGB Model        0.330833     0.708914"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy Data\n",
    "perf_valid= x_valid.copy()\n",
    "perf_valid['response'] = y_valid.copy()\n",
    "\n",
    "# Propensity score\n",
    "perf_valid['score'] = yhat_xgb[:,1].tolist()\n",
    "\n",
    "# sorted clients by score\n",
    "perf_valid = perf_valid.sort_values( 'score', ascending=False )\n",
    "\n",
    "# Compute precision at K\n",
    "precision_atK = precision_at_k(perf_valid, k=20000 )\n",
    "\n",
    "# Compute precision at K\n",
    "recall_atK = recall_at_k(perf_valid, k=20000 )\n",
    "\n",
    "xgb_performance = ml_performance('XGB Model', precision_atK, recall_atK )\n",
    "xgb_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50d43382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T13:34:45.603756Z",
     "start_time": "2023-03-05T13:34:45.399584Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [243909, 76222]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recall \u001b[38;5;241m=\u001b[39m \u001b[43mmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecall_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myhat_xgb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\health_insurance_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2098\u001b[0m, in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1967\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecall_score\u001b[39m(\n\u001b[0;32m   1968\u001b[0m     y_true,\n\u001b[0;32m   1969\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1975\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1976\u001b[0m ):\n\u001b[0;32m   1977\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[0;32m   1978\u001b[0m \n\u001b[0;32m   1979\u001b[0m \u001b[38;5;124;03m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2096\u001b[0m \u001b[38;5;124;03m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2098\u001b[0m     _, r, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2099\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2100\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\health_insurance_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1573\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\health_insurance_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\health_insurance_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\health_insurance_venv\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [243909, 76222]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f26618e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T17:36:04.884987Z",
     "start_time": "2023-02-04T17:36:04.868607Z"
    }
   },
   "source": [
    "### 8.2 - KNN MODEL PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c6408ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:23:38.062746Z",
     "start_time": "2023-03-05T12:23:38.006205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Precision_at_K</th>\n",
       "      <th>Recall_at_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN_Model</td>\n",
       "      <td>0.298285</td>\n",
       "      <td>0.639169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  Precision_at_K  Recall_at_K\n",
       "0  KNN_Model        0.298285     0.639169"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy Data\n",
    "perf_valid = x_valid.copy()\n",
    "perf_valid['response'] = y_valid.copy()\n",
    "\n",
    "# Propensity score\n",
    "perf_valid['score'] = yhat_knn[:,1].tolist()\n",
    "\n",
    "# sorted clients by score\n",
    "perf_valid = perf_valid.sort_values( 'score', ascending=False )\n",
    "\n",
    "# Compute precision at K\n",
    "precision_atK = precision_at_k(perf_valid, k=20000 )\n",
    "\n",
    "# Compute precision at K\n",
    "recall_atK = recall_at_k(perf_valid, k=20000 )\n",
    "\n",
    "KNN_performance = ml_performance('KNN_Model', precision_atK, recall_atK )\n",
    "KNN_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a210e9d",
   "metadata": {},
   "source": [
    "### 8.3 - LGBM MODEL PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9b7ce56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:23:39.837918Z",
     "start_time": "2023-03-05T12:23:39.785037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Precision_at_K</th>\n",
       "      <th>Recall_at_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM Model</td>\n",
       "      <td>0.333233</td>\n",
       "      <td>0.714056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name  Precision_at_K  Recall_at_K\n",
       "0  LGBM Model        0.333233     0.714056"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy Data\n",
    "perf_valid = x_valid.copy()\n",
    "perf_valid['response'] = y_valid.copy()\n",
    "\n",
    "# Propensity score\n",
    "perf_valid['score'] = yhat_lgbm[:,1].tolist()\n",
    "\n",
    "# sorted clients by score\n",
    "perf_valid = perf_valid.sort_values( 'score', ascending=False )\n",
    "\n",
    "# Compute precision at K\n",
    "precision_atK = precision_at_k(perf_valid, k=20000 )\n",
    "\n",
    "# Compute precision at K\n",
    "recall_atK = recall_at_k(perf_valid, k=20000 )\n",
    "\n",
    "lgbm_performance = ml_performance('LGBM Model', precision_atK, recall_atK )\n",
    "lgbm_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61b11d",
   "metadata": {},
   "source": [
    "### 8.3 - PERFORMANCE FOR ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5b69c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:23:48.493471Z",
     "start_time": "2023-03-05T12:23:48.482471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Precision_at_K</th>\n",
       "      <th>Recall_at_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM Model</td>\n",
       "      <td>0.333233</td>\n",
       "      <td>0.714056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB Model</td>\n",
       "      <td>0.330833</td>\n",
       "      <td>0.708914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN_Model</td>\n",
       "      <td>0.298285</td>\n",
       "      <td>0.639169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name  Precision_at_K  Recall_at_K\n",
       "0  LGBM Model        0.333233     0.714056\n",
       "0   XGB Model        0.330833     0.708914\n",
       "0   KNN_Model        0.298285     0.639169"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance = pd.concat( [xgb_performance, KNN_performance, lgbm_performance] )\n",
    "model_performance.sort_values('Precision_at_K', ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a742dc95",
   "metadata": {},
   "source": [
    "## 9 - HYPERPARAMETER FINE TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bf176",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 9.1 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e957f06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T22:03:05.738630Z",
     "start_time": "2023-02-27T22:03:05.700808Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Concatenation train and validation dataset to use in cross-validation\n",
    "df_cv = x_train.copy()\n",
    "df_cv['response'] = y_training\n",
    "\n",
    "df_aux = x_validation.copy()\n",
    "df_aux['response'] = y_validation\n",
    "\n",
    "df_cc = pd.concat([df_cv, df_aux])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8526249a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-27T22:03:57.345970Z",
     "start_time": "2023-02-27T22:03:06.075387Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dictioary with models instantiated\n",
    "models = { 'KNN': knn_model,\n",
    "           'XGB Model': xgb_model,\n",
    "           'LGBM Model': lgbm_model}\n",
    "\n",
    "# Cross-validated models performance\n",
    "model_performance = pd.DataFrame()\n",
    "\n",
    "for key in models.keys():\n",
    "    performance_cv = cross_validation(5, key, models[key], df_cc, 20000)\n",
    "    model_performance = pd.concat([model_performance, performance_cv], axis=1)\n",
    "\n",
    "model_performance.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b77a0",
   "metadata": {},
   "source": [
    "### 9.2 - LGBM Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1c279ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:24:08.612427Z",
     "start_time": "2023-03-05T12:24:08.590784Z"
    }
   },
   "outputs": [],
   "source": [
    "X = x_training\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c136355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:24:08.969492Z",
     "start_time": "2023-03-05T12:24:08.950382Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        #\"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    \n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = lgbm.LGBMClassifier(objective=\"binary\", **param_grid)\n",
    "        model.fit( X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=\"auc\", early_stopping_rounds=100, callbacks=[LightGBMPruningCallback(trial, metric='auc')],  # Add a pruning callback \n",
    "                 )\n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_scores[idx] = log_loss(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c3062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T20:54:58.712107Z",
     "start_time": "2023-03-01T20:53:53.787878Z"
    }
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize' , study_name=\"LGBM Classifier\")\n",
    "func = lambda trial: objective(trial, X, y)\n",
    "study.optimize(func, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cddfcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T20:55:24.457434Z",
     "start_time": "2023-03-01T20:55:24.447959Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "518c43d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:24:12.047681Z",
     "start_time": "2023-03-05T12:24:12.031468Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "'n_estimators': 10000,\n",
    "'learning_rate': 0.14417802056640477,\n",
    "'num_leaves': 1020,\n",
    "'max_depth': 4,\n",
    "'min_data_in_leaf': 9400,\n",
    "'lambda_l1': 20,\n",
    "'lambda_l2': 50,\n",
    "'min_gain_to_split': 11.771936325948504,\n",
    "'bagging_fraction': 0.2,\n",
    "'bagging_freq': 1,\n",
    "'feature_fraction': 0.6000000000000001}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab9d90",
   "metadata": {},
   "source": [
    "### 9.3 - XGB Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a5938d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:33:32.767231Z",
     "start_time": "2023-03-02T22:33:32.757119Z"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a0c80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:33:33.217304Z",
     "start_time": "2023-03-02T22:33:33.193302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Union of training dataset to select best parameters for XGB Model\n",
    "x_train_xgb = pd.concat([x_training, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866b8a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T21:55:25.905829Z",
     "start_time": "2023-03-02T21:55:25.892311Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "     'n_estimators': [1000, 1500, 2000, 2500], \n",
    "     'eta': [0.01, 0.03],\n",
    "     'max_depth': [3, 5, 9],\n",
    "     'subsample': [0.1, 0.5, 0.7],\n",
    "     'colsample_bytree': [0.3, 0.7, 0.9],\n",
    "     'min_child_weight':[3, 8, 15] }\n",
    "\n",
    "MAX_EVAL = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7774795",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:17:51.033055Z",
     "start_time": "2023-03-02T22:07:55.551000Z"
    }
   },
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame()\n",
    "\n",
    "for i in range( MAX_EVAL ):\n",
    "# choose values for parameters randomly\n",
    "    hp = { k: random.sample(v, 1)[0] for k, v in param.items() }\n",
    "    print( hp )\n",
    "    \n",
    "#    # model\n",
    "    model_xgb = XGBClassifier( scale_pos_weight=7.2,\n",
    "                               colsample_bytree =hp['colsample_bytree'],\n",
    "                               subsample = hp['subsample'],\n",
    "                               objective='binary:logistic', \n",
    "                               n_estimators=hp['n_estimators'], \n",
    "                               max_depth=hp['max_depth'],\n",
    "                               min_child_weight = hp['min_child_weight'],\n",
    "                               eta=hp['eta'])\n",
    "    # performance\n",
    "    result = cross_validation(2, 'xgb classifier', model_xgb, x_train_xgb, 20000)\n",
    "    final_result = pd.concat( [final_result, result] )\n",
    "\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0ee87",
   "metadata": {},
   "source": [
    "###  9.3.2 - Last model training with all datas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7415b67",
   "metadata": {},
   "source": [
    "#### 9.3.2.1 - Data preparation applied on validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da3debd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:24:41.956585Z",
     "start_time": "2023-03-05T12:24:41.869027Z"
    }
   },
   "outputs": [],
   "source": [
    "x_valid = data_preparation( x_valid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96633515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:24:42.300758Z",
     "start_time": "2023-03-05T12:24:42.213442Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test = data_preparation( x_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982ff47",
   "metadata": {},
   "source": [
    "#### 9.3.2.2 - Union of training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e7dd1b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:24:42.941013Z",
     "start_time": "2023-03-05T12:24:42.918007Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_treino = pd.concat([ x_training, x_valid ] )\n",
    "y_train_treino = pd.concat([ y_train, y_valid ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a62cfd",
   "metadata": {},
   "source": [
    "#### 9.3.2.3 - Generalization capacity of LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edb17247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:24:59.387330Z",
     "start_time": "2023-03-05T12:24:45.264466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.771936325948504, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.771936325948504\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "lgbm_model = lgbm.LGBMClassifier(**params )\n",
    "\n",
    "# Model Training\n",
    "model_lgbm = lgbm_model.fit( x_train_treino, y_train_treino )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a2b3362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:24:59.434208Z",
     "start_time": "2023-03-05T12:24:59.389832Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Prediction\n",
    "yhat_lgbm = model_lgbm.predict_proba( x_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04cbc24b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:24:59.495313Z",
     "start_time": "2023-03-05T12:24:59.436210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Precision_at_K</th>\n",
       "      <th>Recall_at_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM Model</td>\n",
       "      <td>0.305685</td>\n",
       "      <td>0.806065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name  Precision_at_K  Recall_at_K\n",
       "0  LGBM Model        0.305685     0.806065"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy Data\n",
    "df_test = x_test.copy()\n",
    "df_test['response'] = y_test.copy()\n",
    "\n",
    "# Propensity score\n",
    "df_test['score'] = yhat_lgbm[:,1].tolist()\n",
    "\n",
    "# sorted clients by score\n",
    "df_test = df_test.sort_values( 'score', ascending=False )\n",
    "\n",
    "# Compute precision at K\n",
    "precision_atK = precision_at_k(df_test, k=20000 )\n",
    "\n",
    "# Compute precision at K\n",
    "recall_atK = recall_at_k(df_test, k=20000 )\n",
    "\n",
    "lgbm_performance_cv = ml_performance('LGBM Model', precision_atK, recall_atK )\n",
    "lgbm_performance_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22900979",
   "metadata": {},
   "source": [
    "#### 9.3.2.4 - Generalization capacity of XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18f1961d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:26:16.298081Z",
     "start_time": "2023-03-05T12:25:10.962360Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGB CROSS VALIDATION\n",
    "\n",
    "# model definition\n",
    "model_xgb_cv = XGBClassifier( scale_pos_weight=7.2,\n",
    "                              colsample_bytree = 0.3,\n",
    "                              subsample = 0.5,\n",
    "                              objective='binary:logistic', \n",
    "                              n_estimators=1500, \n",
    "                              max_depth=9,\n",
    "                              min_child_weight = 3,\n",
    "                              eta= 0.03 )\n",
    "\n",
    "# model training\n",
    "model_xgb_cv.fit( x_training, y_train )\n",
    "\n",
    "# model prediction - The generalization POWER\n",
    "yhat_xgb_cv = model_xgb_cv.predict_proba( x_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40cc77d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T12:26:16.360849Z",
     "start_time": "2023-03-05T12:26:16.301081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Precision_at_K</th>\n",
       "      <th>Recall_at_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB Model</td>\n",
       "      <td>0.313234</td>\n",
       "      <td>0.825972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  Precision_at_K  Recall_at_K\n",
       "0  XGB Model        0.313234     0.825972"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy Data\n",
    "df_test = x_test.copy()\n",
    "df_test['response'] = y_test.copy()\n",
    "\n",
    "# Propensity score\n",
    "df_test['score'] = yhat_xgb_cv[:,1].tolist()\n",
    "\n",
    "# sorted clients by score\n",
    "df_test = df_test.sort_values( 'score', ascending=False )\n",
    "\n",
    "# Compute precision at K\n",
    "precision_atK = precision_at_k(df_test, k=20000 )\n",
    "\n",
    "# Compute precision at K\n",
    "recall_atK = recall_at_k(df_test, k=20000 )\n",
    "\n",
    "xgb_performance_cv = ml_performance('XGB Model', precision_atK, recall_atK )\n",
    "xgb_performance_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7739b14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T22:37:34.164796Z",
     "start_time": "2023-03-02T22:37:34.150802Z"
    }
   },
   "outputs": [],
   "source": [
    "#pickle.dump(lgbm_model, open('C:/Users/perot/Documents/ds_repos/projects/Health_Insurance_Cross_Sell/src/models/lgbm_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a55409",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 10 - DEPLOYING MODEL TO PRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e92906",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 10.1 - HEALTHINSURANCE CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa080b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import inflection\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "class HealthInsurance:\n",
    "    \n",
    "    def __init__( self ):\n",
    "        self.home_path                                = ''\n",
    "        self.frequency_encode_policy_sales_scaler     = pickle.load( open( self.home_path + 'src/features/frequency_encode_policy_sales_scaler.pkl', 'rb') )\n",
    "        self.frequency_encode_region_code_scaler      = pickle.load( open( self.home_path + 'src/features/frequency_encode_region_code_scaler.pkl', 'rb') )\n",
    "        self.target_encode_gender_scaler              = pickle.load( open( self.home_path + 'src/features/target_encode_gender_scaler.pkl', 'rb') )\n",
    "        self.target_encode_vintage_month_scaler       = pickle.load( open( self.home_path + 'src/features/target_encode_vintage_month_scaler.pkl', 'rb') )\n",
    "        self.age_scaler                               = pickle.load( open( self.home_path + 'src/features/age_scaler.pkl', 'rb') )\n",
    "        self.avg_vehicle_damage_region_code_scaler    = pickle.load( open( self.home_path + 'src/features/age_scaler.pkl', 'rb') )\n",
    "        self.avg_vintage_age_scaler                   = pickle.load( open( self.home_path + 'src/features/avg_vintage_age_scaler.pkl', 'rb') )\n",
    "        self.vintage_scaler                           = pickle.load( open( self.home_path + 'src/features/vintage_scaler.pkl', 'rb') )\n",
    "        self.age_premium_scaler                       = pickle.load( open( self.home_path + 'src/features/age_premium_scaler.pkl', 'rb') )\n",
    "        self.annual_premium_scaler                    = pickle.load( open( self.home_path + 'src/features/age_premium_scaler.pkl', 'rb') )\n",
    "        self.avg_day_premium_policy_scaler            = pickle.load( open( self.home_path + 'src/features/avg_day_premium_policy_scaler.pkl', 'rb') )\n",
    "        self.day_premium_scaler                       = pickle.load( open( self.home_path + 'src/features/day_premium_scaler.pkl', 'rb') )\n",
    "        self.median_premium_by_region_scaler          = pickle.load( open( self.home_path + 'src/features/median_premium_by_region_scaler.pkl', 'rb') )\n",
    "        self.region_premium_scaler                    = pickle.load( open( self.home_path + 'src/features/region_premium_scaler.pkl', 'rb') )\n",
    "    \n",
    "    def data_cleaning( self, df5 ):\n",
    " \n",
    "        ## rename Columns\n",
    "        cols_old = ['id', 'Gender', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
    "\n",
    "        snakecase = lambda x: inflection.underscore( x )\n",
    "        cols_new = list( map( snakecase, cols_old ) )\n",
    "        \n",
    "        # rename\n",
    "        df5.columns = cols_new\n",
    "        \n",
    "        return( df5 )\n",
    "\n",
    "    def feature_engineering( self, df5 ):\n",
    "        \n",
    "        # Fitting vehicle_age column\n",
    "        df5['vehicle_age'] = df5['vehicle_age'].apply(lambda x: 1 if (x == '< 1 Year') else 2 if (x == '1-2 Year') else 3)\n",
    "\n",
    "        # Fitting vehicle_damage column\n",
    "        df5['vehicle_damage'] = df5['vehicle_damage'].apply(lambda x: 1 if (x == 'Yes') else 0)\n",
    "        \n",
    "        # median_premium_by_region\n",
    "        dict_region_code = df5[['annual_premium', 'region_code']].groupby('region_code').median().to_dict(orient='dict')['annual_premium']\n",
    "        df5['median_premium_by_region'] = df5['region_code'].map(dict_region_code)\n",
    "\n",
    "        # moda policy sales chanel por idade\n",
    "        mode_policy_per_age = df5[['age', 'policy_sales_channel']].groupby('age').agg(pd.Series.mode).to_dict(orient='dict')['policy_sales_channel']\n",
    "        df5['mode_policy_per_age'] = df5['age'].map(mode_policy_per_age)\n",
    "\n",
    "        # Media de carros danificados por idade\n",
    "        avg_carros_danificados_idade = df5[['age', 'vehicle_damage']].groupby('age').mean().to_dict(orient='dict')['vehicle_damage']\n",
    "        df5['avg_vehicle_damage_per_age'] = df5['age'].map(avg_carros_danificados_idade)\n",
    "\n",
    "        # Media de carros danificados por regiao\n",
    "        avg_carros_danificados_regiao = df5[['age', 'region_code']].groupby('age').mean().to_dict(orient='dict')['region_code']\n",
    "        df5['avg_vehicle_damage_region_code'] = df5['age'].map(avg_carros_danificados_regiao)\n",
    "\n",
    "        # age_group feature creation\n",
    "        df5['age_group'] = df5['age'].apply(lambda x: 1 if (x >= 18 | x < 30 ) else 2 if (x >= 30 | x < 60 ) else 3)\n",
    "\n",
    "        # vintage_month feature cration\n",
    "        df5['vintage_month'] = round(df5['vintage'] / 31)\n",
    "\n",
    "        # day_premium feature creation\n",
    "        df5['day_premium'] = df5['annual_premium']/df5['vintage']\n",
    "\n",
    "        # age_premium feature cration\n",
    "        df5['age_premium'] = df5['annual_premium']/df5['age']\n",
    "\n",
    "        # Calculating Median Annual Premium by Region_code\n",
    "        premium_rc = df5[['annual_premium', 'region_code']].groupby('region_code').median().to_dict(orient='dict')['annual_premium']\n",
    "        df5['region_premium'] = df5['region_code'].map(premium_rc)\n",
    "\n",
    "        # Calculating Median Aday_premium per policy_sales_channel\n",
    "        day_premium_psc = df5[['day_premium', 'policy_sales_channel']].groupby('policy_sales_channel').mean().to_dict(orient='dict')['day_premium']\n",
    "        df5['avg_day_premium_policy'] = df5['policy_sales_channel'].map(day_premium_psc)\n",
    "\n",
    "        # avg vintage per age\n",
    "        avg_vintage_per_age = df5[['age', 'vintage']].groupby('age').mean().to_dict(orient='dict')['vintage']\n",
    "        df5['avg_vintage_age'] = df5['age'].map(avg_vintage_per_age)\n",
    "        \n",
    "        return( df5 )\n",
    "    \n",
    "    def data_preparation( self, df5 ):\n",
    "              \n",
    "        # STANDARDIZATION\n",
    "\n",
    "        # annual premium\n",
    "        df5['annual_premium'] = self.annual_premium_scaler.transform( df5[['annual_premium']].values )\n",
    "\n",
    "        # age_premium\n",
    "        df5['age_premium'] = self.age_premium_scaler.transform( df5[['age_premium']].values )\n",
    "\n",
    "        # day_premium\n",
    "        df5['day_premium'] = self.day_premium_scaler.transform( df5[['day_premium']].values )\n",
    "\n",
    "        # avg_day_premium_policy\n",
    "        df5['avg_day_premium_policy'] = self.avg_day_premium_policy_scaler.transform( df5[['avg_day_premium_policy']].values )\n",
    "\n",
    "        # median_premium_by_region\n",
    "        df5['median_premium_by_region'] = self.median_premium_by_region_scaler.transform( df5[['median_premium_by_region']].values )\n",
    "\n",
    "        # region_premium\n",
    "        df5['region_premium'] = self.region_premium_scaler.transform( df5[['region_premium']].values )\n",
    "\n",
    "\n",
    "\n",
    "        # REESCALING\n",
    "\n",
    "        # age\n",
    "        df5['age'] = self.age_scaler.transform( df5[['age']].values )\n",
    "\n",
    "        # vintage\n",
    "        df5['vintage'] = self.vintage_scaler.transform( df5[['vintage']].values )\n",
    "\n",
    "        # avg_vintage_age\n",
    "        df5['avg_vintage_age'] = self.avg_vintage_age_scaler.transform( df5[['avg_vintage_age']].values )\n",
    "\n",
    "        # vintage_month\n",
    "        df5['vintage_month'] = self.vintage_scaler.transform( df5[['vintage_month']].values )\n",
    "\n",
    "        # avg_vehicle_damage_region_code\n",
    "        df5['avg_vehicle_damage_region_code'] = self.avg_vehicle_damage_region_code_scaler.transform( df5[['avg_vehicle_damage_region_code']].values )\n",
    "\n",
    "\n",
    "\n",
    "        # ENCODER\n",
    "\n",
    "        # policy sales channel\n",
    "        df5.loc[:, 'policy_sales_channel'] = df5['policy_sales_channel'].map( self.frequency_encode_policy_sales_scaler )\n",
    "\n",
    "        # region code\n",
    "        df5.loc[:, 'region_code'] = df5['region_code'].map( self.frequency_encode_region_code_scaler )\n",
    "\n",
    "        # gender\n",
    "        df5.loc[:, 'gender'] = df5['gender'].map( self.target_encode_gender_scaler )\n",
    "\n",
    "        # vintage_month\n",
    "        df5.loc[:, 'vintage_month'] = df5['vintage_month'].map( self.target_encode_vintage_month_scaler )\n",
    "\n",
    "        # FILL NAN VALUES\n",
    "        x_valid = x_valid.fillna(0)\n",
    "        \n",
    "        # Feature Selection\n",
    "        cols_selected = ['vehicle_damage','previously_insured','vintage','day_premium','age_premium','annual_premium','vintage_month','region_code','avg_vehicle_damage_per_age','policy_sales_channel','age','median_premium_by_region','region_premium',\n",
    "                         'avg_day_premium_policy','vehicle_age','avg_vehicle_damage_region_code','avg_vintage_age','gender']\n",
    "        \n",
    "        return df5[cols_selected]\n",
    "    \n",
    "\n",
    "    def get_prediction( self, model, original_data, test_data ):\n",
    "        # prediction\n",
    "        pred = model.predict_proba( test_data )\n",
    "        \n",
    "        # join pred into the original data\n",
    "        original_data['score'] = pred[:, 1].tolist()\n",
    "        \n",
    "        return original_data.to_json( orient='records', date_format='iso' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce5926",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 10.2 - API HANDLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985f9b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from flask                           import Flask, request, Response\n",
    "from healthinsurance.healthinsurance import HealthInsurance\n",
    "\n",
    "# logading model\n",
    "model = pickle.load( open( 'src/models/xgb_model.pkl', 'rb' ) )\n",
    "                          \n",
    "# initialize API\n",
    "app = Flask( __name__ )\n",
    "\n",
    "@app.route( '/healthinsurance/predict', methods=['POST'] )\n",
    "def health_insurance_predict():\n",
    "    test_json = request.get_json()\n",
    "    \n",
    "    if test_json: #there is data\n",
    "               \n",
    "        if isinstance( test_json, dict ): # unique example\n",
    "            test_raw = pd.DataFrame( test_json, index=[0] )\n",
    "    \n",
    "        else:\n",
    "            test_raw = pd.DataFrame( test_json, columns=test_json[0].keys() ) # multiple examples\n",
    "            \n",
    "        # Instantiate Rossmann Class\n",
    "        pipeline = HealthInsurance()\n",
    "\n",
    "        # data cleaning\n",
    "        df1 = pipeline.data_cleaning( test_raw )\n",
    "              \n",
    "        # feature engineering\n",
    "        df2 = pipeline.feature_engineering( df1 )\n",
    "\n",
    "        # Data Preparation\n",
    "        df3 = pipeline.data_preparation( df2 )\n",
    "                              \n",
    "        # prediction\n",
    "        df_response = pipeline.get_prediction( model, test_raw, df3 )\n",
    "        \n",
    "        return df_response\n",
    "        \n",
    "    else:\n",
    "        return Response( '{}', status=200, mimetype='application/json' )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run('0.0.0.0')\n",
    "\n",
    "#    port = os.environ.get('PORT', 5000)\n",
    "#    app.run( host='0.0.0.0', port=port )"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
